from __future__ import annotations

import os
import json
import logging
from typing import Optional, List

from pydantic import BaseModel

# Vector DB imports (for chat_with_contract RAG system)
try:
    from langchain_community.document_loaders import PyPDFLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    from langchain_chroma import Chroma
    VECTOR_DB_AVAILABLE = True
except ImportError as e:
    VECTOR_DB_AVAILABLE = False
    logging.warning(f"Vector DB dependencies not available: {e}. Chat functionality will be limited.")

DEMO_MODE = False

CLEANING_RULES = """
**[ì‘ì—… 1: í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ì œ (Text Cleaning)] - ì¤‘ìš”!**
ê³„ì•½ì„œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ë•Œ, ë‹¤ìŒ 'ì¤„ë°”ê¿ˆ ì²˜ë¦¬ ê·œì¹™'ì„ ì—„ê²©í•˜ê²Œ ì ìš©í•˜ì—¬ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë§Œë“œì„¸ìš”.

1. **ë¬¸ì¥ ì—°ê²° (Line Merge):**
   - ë¬¸ì¥ì´ ë¬¸ë²•ì ìœ¼ë¡œ ëë‚˜ì§€ ì•Šì•˜ëŠ”ë° ì¤„ë°”ê¿ˆ ë¬¸ì(\\n)ê°€ ìˆëŠ” ê²½ìš°, ì´ë¥¼ ì‚­ì œí•˜ê³  **ê³µë°±(ë„ì–´ì“°ê¸°)ìœ¼ë¡œ ëŒ€ì²´**í•˜ì—¬ ì•ë’¤ ë¬¸ì¥ì„ ì—°ê²°í•˜ì„¸ìš”.
   - ì˜ˆì‹œ: "ê·¼ë¡œìëŠ” ê°‘ì˜ ì§€ì‹œì—\\në”°ë¼ì•¼ í•œë‹¤" -> "ê·¼ë¡œìëŠ” ê°‘ì˜ ì§€ì‹œì— ë”°ë¼ì•¼ í•œë‹¤"

2. **êµ¬ì¡° ìœ ì§€ (Structure Keep):**
   - ë¬¸ë‹¨ì´ ë°”ë€Œê±°ë‚˜, ì¡°í•­ì´ êµ¬ë¶„ë˜ëŠ” ê²½ìš°(ì˜ˆ: ì œ1ì¡°, 1., ê°€. ë“±)ì—ëŠ” ì¤„ë°”ê¿ˆì„ ìœ ì§€í•˜ì„¸ìš”.
   - í‘œë‚˜ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„°ëŠ” êµ¬ì¡°ê°€ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì¤„ë°”ê¿ˆì„ ë³´ì¡´í•˜ì„¸ìš”.
"""

# [ë°±ì—”ë“œ ì‚½ì…ìš©] 6ëŒ€ ë²•ë ¹ ê°•í–‰ê·œì • ìœ„ë°˜ íƒì§€ ë°ì´í„°ì…‹
# ì´ ë¦¬ìŠ¤íŠ¸ëŠ” AIê°€ ë¶„ì„í•  ë•Œ 'ì •ë‹µì§€'ë¡œ ì°¸ê³ í•©ë‹ˆë‹¤.
MANDATORY_RISK_CLAUSES = [
    # 1. ê·¼ë¡œê¸°ì¤€ë²• ì œ20ì¡° (ìœ„ì•½ê¸ˆ ì˜ˆì • ê¸ˆì§€) - ì ˆëŒ€ ë¬´íš¨
    {
        "clause_id": "mandatory_labor_01",
        "category": "ğŸš¨ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜",
        "risk_pattern": "í‡´ì‚¬ ì‹œ ìœ„ì•½ê¸ˆ, ì†í•´ë°°ìƒì•¡ì„ ë¯¸ë¦¬ ê¸ˆì•¡ìœ¼ë¡œ ì •í•´ë‘ ",
        "legal_reference": "ê·¼ë¡œê¸°ì¤€ë²• ì œ20ì¡° (ìœ„ì•½ ì˜ˆì • ê¸ˆì§€)",
        "explanation": "ê·¼ë¡œìê°€ ê°‘ìê¸° ê·¸ë§Œë‘”ë‹¤ê³  í•´ì„œ ë¯¸ë¦¬ ì •í•´ì§„ ë²Œê¸ˆ(ìœ„ì•½ê¸ˆ)ì„ ë‚´ê²Œ í•˜ëŠ” ê±´ ë¶ˆë²•ì…ë‹ˆë‹¤. ì‹¤ì œ ë°œìƒí•œ ì†í•´ë§Œ ì²­êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "script": "ê·¼ë¡œê¸°ì¤€ë²• ì œ20ì¡°ì— ì˜ê±°, ê·¼ë¡œê³„ì•½ ë¶ˆì´í–‰ì— ëŒ€í•œ ìœ„ì•½ê¸ˆ ì˜ˆì • ì•½ì •ì€ ë¬´íš¨ì…ë‹ˆë‹¤. í•´ë‹¹ ì¡°í•­ ì‚­ì œë¥¼ ìš”ì²­í•©ë‹ˆë‹¤."
    },

    # 2. ê·¼ë¡œê¸°ì¤€ë²• ì œ56ì¡° (ì—°ì¥/ì•¼ê°„/íœ´ì¼ê·¼ë¡œ ê°€ì‚°ìˆ˜ë‹¹) - 50% ê°€ì‚° í•„ìˆ˜
    {
        "clause_id": "mandatory_labor_02",
        "category": "ğŸš¨ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜",
        "risk_pattern": "ì—°ì¥ê·¼ë¡œ, ì•¼ê°„ê·¼ë¡œ, íœ´ì¼ê·¼ë¡œì— ëŒ€í•œ ê°€ì‚°ìˆ˜ë‹¹(50%)ì´ ì—†ê±°ë‚˜ í†µìƒì„ê¸ˆë§Œ ì§€ê¸‰",
        "legal_reference": "ê·¼ë¡œê¸°ì¤€ë²• ì œ56ì¡° (ì—°ì¥Â·ì•¼ê°„ ë° íœ´ì¼ ê·¼ë¡œ)",
        "explanation": "ì•¼ê·¼, ë°¤ 10ì‹œ ì´í›„ ê·¼ë¬´, ì£¼ë§ ê·¼ë¬´ë¥¼ í•  ë•ŒëŠ” ì‹œê¸‰ì˜ 1.5ë°°(50% ê°€ì‚°)ë¥¼ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. í‰ì¼ ì‹œê¸‰ë§Œ ì£¼ëŠ” ê±´ ë¶ˆë²•ì…ë‹ˆë‹¤.",
        "script": "ê·¼ë¡œê¸°ì¤€ë²• ì œ56ì¡°ì— ë”°ë¼ ì—°ì¥Â·ì•¼ê°„Â·íœ´ì¼ê·¼ë¡œ ì‹œ í†µìƒì„ê¸ˆì˜ 50%ë¥¼ ê°€ì‚°í•˜ì—¬ ì§€ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤. ê°€ì‚°ìˆ˜ë‹¹ ì§€ê¸‰ì„ ìš”ì²­í•©ë‹ˆë‹¤."
    },

    # 3. ìµœì €ì„ê¸ˆë²• (ìµœì €ì„ê¸ˆ ë¯¸ë‹¬) - í˜•ì‚¬ì²˜ë²Œ ëŒ€ìƒ
    {
        "clause_id": "mandatory_wage_01",
        "category": "ğŸš¨ ìµœì €ì„ê¸ˆë²• ìœ„ë°˜",
        "risk_pattern": "ì‹œê¸‰ í™˜ì‚° ì‹œ ë²•ì • ìµœì €ì„ê¸ˆ(2025ë…„ 10,030ì›)ë³´ë‹¤ ë‚®ìŒ",
        "legal_reference": "ìµœì €ì„ê¸ˆë²• ì œ6ì¡° (ìµœì €ì„ê¸ˆì˜ íš¨ë ¥)",
        "explanation": "2025ë…„ ìµœì €ì‹œê¸‰ì€ 10,030ì›ì…ë‹ˆë‹¤. ì›”ê¸‰ì„ ê·¼ë¬´ì‹œê°„ìœ¼ë¡œ ë‚˜ëˆ´ì„ ë•Œ ì´ë³´ë‹¤ ë‚®ìœ¼ë©´ í˜•ì‚¬ì²˜ë²Œ ëŒ€ìƒì…ë‹ˆë‹¤.",
        "script": "ê³„ì•½ì„œìƒ ê¸‰ì—¬ë¥¼ ì‹œê¸‰ìœ¼ë¡œ í™˜ì‚°í•˜ë©´ ìµœì €ì„ê¸ˆë²•ì— ë¯¸ë‹¬í•©ë‹ˆë‹¤. 2025ë…„ ìµœì €ì‹œê¸‰ 10,030ì› ê¸°ì¤€ìœ¼ë¡œ ì¬ê³„ì‚°í•˜ì—¬ ê³„ì•½ì„œ ìˆ˜ì •ì„ ìš”ì²­í•©ë‹ˆë‹¤."
    },

    # 4. ê·¼ë¡œê¸°ì¤€ë²• ì œ54ì¡° (íœ´ê²Œì‹œê°„ ë¯¸ë¶€ì—¬) - ì˜ë¬´ ìœ„ë°˜
    {
        "clause_id": "mandatory_labor_03",
        "category": "ğŸš¨ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜",
        "risk_pattern": "4ì‹œê°„ ê·¼ë¬´ ì‹œ 30ë¶„, 8ì‹œê°„ ê·¼ë¬´ ì‹œ 1ì‹œê°„ì˜ íœ´ê²Œì‹œê°„ì„ ë³´ì¥í•˜ì§€ ì•ŠìŒ",
        "legal_reference": "ê·¼ë¡œê¸°ì¤€ë²• ì œ54ì¡° (íœ´ê²Œ)",
        "explanation": "4ì‹œê°„ ì¼í•˜ë©´ 30ë¶„, 8ì‹œê°„ ì¼í•˜ë©´ 1ì‹œê°„ ì‰¬ëŠ” ì‹œê°„ì„ ì˜ë¬´ì ìœ¼ë¡œ ì¤˜ì•¼ í•©ë‹ˆë‹¤. 'ì•Œì•„ì„œ ì‰¬ë¼'ëŠ” ì‹ì€ ë¶ˆë²•ì…ë‹ˆë‹¤.",
        "script": "ê·¼ë¡œê¸°ì¤€ë²• ì œ54ì¡°ì— ë”°ë¼ ê·¼ë¡œì‹œê°„ì´ 4ì‹œê°„ì¸ ê²½ìš° 30ë¶„ ì´ìƒ, 8ì‹œê°„ì¸ ê²½ìš° 1ì‹œê°„ ì´ìƒì˜ íœ´ê²Œì‹œê°„ì„ ê·¼ë¡œì‹œê°„ ë„ì¤‘ì— ë¶€ì—¬í•´ì•¼ í•©ë‹ˆë‹¤."
    },

    # 5. ê·¼ë¡œìí‡´ì§ê¸‰ì—¬ë³´ì¥ë²• (í‡´ì§ê¸ˆ ë¯¸ì§€ê¸‰) - 1ë…„ ì´ìƒ ê·¼ë¬´ ì‹œ í•„ìˆ˜
    {
        "clause_id": "mandatory_retirement_01",
        "category": "ğŸš¨ ê·¼ë¡œìí‡´ì§ê¸‰ì—¬ë³´ì¥ë²• ìœ„ë°˜",
        "risk_pattern": "í‡´ì§ê¸ˆ ì—†ìŒ, í‡´ì§ê¸ˆì€ ì›”ê¸‰ì— í¬í•¨, í‡´ì§ê¸ˆ ì§€ê¸‰ ì•ˆ í•¨ ë“±ì˜ ë¬¸êµ¬",
        "legal_reference": "ê·¼ë¡œìí‡´ì§ê¸‰ì—¬ë³´ì¥ë²• ì œ8ì¡° (í‡´ì§ê¸ˆì œë„ì˜ ì„¤ì •)",
        "explanation": "1ë…„ ì´ìƒ, ì£¼ 15ì‹œê°„ ì´ìƒ ì¼í•˜ë©´ ë°˜ë“œì‹œ í‡´ì§ê¸ˆì„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. 'ì›”ê¸‰ì— í¬í•¨'ì´ë¼ëŠ” ë§ì€ ìœ„ë²•ì…ë‹ˆë‹¤.",
        "script": "ê·¼ë¡œìí‡´ì§ê¸‰ì—¬ë³´ì¥ë²• ì œ8ì¡°ì— ë”°ë¼ ê³„ì†ê·¼ë¡œê¸°ê°„ 1ë…„ì— ëŒ€í•˜ì—¬ 30ì¼ë¶„ ì´ìƒì˜ í‰ê· ì„ê¸ˆì„ í‡´ì§ê¸ˆìœ¼ë¡œ ì§€ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤. í‡´ì§ê¸ˆ ì¡°í•­ ì¶”ê°€ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤."
    },

    # 6. í•˜ë„ê¸‰ë²• (ë¶€ë‹¹í•œ íŠ¹ì•½ ê¸ˆì§€) - ê°‘ì§ˆ ë°©ì§€
    {
        "clause_id": "mandatory_subcontract_01",
        "category": "ğŸš¨ í•˜ë„ê¸‰ë²• ìœ„ë°˜",
        "risk_pattern": "ë¬´í•œ ìˆ˜ì •, íšŸìˆ˜ ì œí•œ ì—†ì´ ìˆ˜ì •, ê°‘ì´ ë§Œì¡±í•  ë•Œê¹Œì§€ ë¬´ìƒ ìˆ˜ì • ë“±ì˜ ë¬¸êµ¬",
        "legal_reference": "í•˜ë„ê¸‰ê±°ë˜ ê³µì •í™”ì— ê´€í•œ ë²•ë¥  ì œ3ì¡°ì˜4 (ë¶€ë‹¹í•œ íŠ¹ì•½ ê¸ˆì§€)",
        "explanation": "ëˆì€ ì •í•´ì ¸ ìˆëŠ”ë° ì¼ì€ ëì—†ì´ ì‹œí‚¤ëŠ” ê±´ ë¶ˆë²•ì…ë‹ˆë‹¤. 'ë¬´ìƒ ìˆ˜ì • 2íšŒ' ì²˜ëŸ¼ íšŸìˆ˜ë¥¼ ë”± ì •í•´ì•¼ í•©ë‹ˆë‹¤.",
        "script": "ë¬´ì œí•œ ìˆ˜ì • ìš”êµ¬ëŠ” í•˜ë„ê¸‰ë²•ìƒ ë¶€ë‹¹í•œ íŠ¹ì•½ì— í•´ë‹¹í•  ì†Œì§€ê°€ í½ë‹ˆë‹¤. í†µìƒì ì¸ ê¸°ì¤€ì¸ 'ë¬´ìƒ ìˆ˜ì • 2íšŒ, ì´í›„ ìœ ìƒ ì§„í–‰'ìœ¼ë¡œ ìˆ˜ì •ì„ ìš”ì²­í•©ë‹ˆë‹¤."
    }
]

class AnalysisItem(BaseModel):
    category: str
    original_text: str
    explanation: str
    script: str

class ContractAnalysisResult(BaseModel):
    extracted_text: str
    risk_clauses: list[AnalysisItem]
    summary: str


def get_demo_result() -> ContractAnalysisResult:
    """Return demo analysis result for testing without API calls."""

    demo_contract_text = """ê·¼ë¡œê³„ì•½ì„œ

1. ê·¼ë¡œê³„ì•½ê¸°ê°„: 2024ë…„ 1ì›” 1ì¼ ~ 2024ë…„ 12ì›” 31ì¼

2. ê·¼ë¬´ì¥ì†Œ: ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123, ABC ì£¼ì‹íšŒì‚¬

3. ì—…ë¬´ë‚´ìš©: ë§¤ì¥ íŒë§¤ ë° ê³ ê° ì‘ëŒ€

4. ê·¼ë¡œì‹œê°„: 09:00 ~ 21:00 (íœ´ê²Œì‹œê°„ ë³„ë„ í˜‘ì˜)

5. ì„ê¸ˆ
   - ì‹œê¸‰: 9,860ì›
   - ì„ê¸ˆì§€ê¸‰ì¼: ìµì›” 15ì¼
   - ì§€ê¸‰ë°©ë²•: ê³„ì¢Œì´ì²´

6. íœ´ì¼: ì£¼ 1ì¼ (ì‚¬ì—…ì¥ ì‚¬ì •ì— ë”°ë¼ ë³€ê²½ ê°€ëŠ¥)

7. í•´ê³ : íšŒì‚¬ëŠ” ì—…ë¬´ìƒ í•„ìš”ì— ë”°ë¼ ê·¼ë¡œìë¥¼ ì¦‰ì‹œ í•´ê³ í•  ìˆ˜ ìˆë‹¤.

8. ê¸°íƒ€ì‚¬í•­
   - ê·¼ë¡œìëŠ” ì—…ë¬´ìƒ ë°œìƒí•œ ì†í•´ì— ëŒ€í•´ ì „ì•¡ ë°°ìƒí•´ì•¼ í•œë‹¤.
   - í‡´ì§ í›„ 1ë…„ê°„ ë™ì¢…ì—…ê³„ ì·¨ì—…ì„ ê¸ˆì§€í•œë‹¤.

ë³¸ì¸ì€ ìœ„ ê·¼ë¡œì¡°ê±´ì„ í™•ì¸í•˜ê³  ì´ì— ë™ì˜í•©ë‹ˆë‹¤.

2024ë…„ 1ì›” 1ì¼
ê·¼ë¡œì: _____________ (ì„œëª…)
ì‚¬ìš©ì: ABC ì£¼ì‹íšŒì‚¬ ëŒ€í‘œ í™ê¸¸ë™ (ì¸)"""

    demo_analysis = [
        AnalysisItem(
            category="ğŸš¨ íœ´ê²Œì‹œê°„ ë¯¸ëª…ì‹œ",
            original_text="09:00 ~ 21:00 (íœ´ê²Œì‹œê°„ ë³„ë„ í˜‘ì˜)",
            explanation="12ì‹œê°„ ê·¼ë¬´ë¼ë©´ ìµœì†Œ 1ì‹œê°„ 30ë¶„ì˜ íœ´ê²Œì‹œê°„ì´ ë²•ìœ¼ë¡œ ë³´ì¥ë˜ì–´ì•¼ í•´ìš”. 'ë³„ë„ í˜‘ì˜'ë¼ëŠ” í‘œí˜„ì€ íœ´ê²Œì‹œê°„ì„ ì•ˆ ì¤„ ìˆ˜ë„ ìˆë‹¤ëŠ” ëœ»ì´ì—ìš”. ê·¼ë¡œê¸°ì¤€ë²• ì œ54ì¡°ì— ë”°ë¥´ë©´ 8ì‹œê°„ ì¼í•  ë•Œ 1ì‹œê°„ ì´ìƒ ì‰¬ì–´ì•¼ í•˜ëŠ”ë°, ì´ê²Œ ê³„ì•½ì„œì— ëª…í™•í•˜ê²Œ ì•ˆ ì í˜€ ìˆì–´ì„œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆì–´ìš”.",
            script="íœ´ê²Œì‹œê°„ì´ 'ë³„ë„ í˜‘ì˜'ë¡œ ë˜ì–´ ìˆëŠ”ë°, ê·¼ë¡œê¸°ì¤€ë²• ì œ54ì¡°ì— ë”°ë¥´ë©´ 8ì‹œê°„ ì´ˆê³¼ ê·¼ë¬´ ì‹œ 1ì‹œê°„ ì´ìƒì˜ íœ´ê²Œì‹œê°„ì´ ë³´ì¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ê³„ì•½ì„œì— êµ¬ì²´ì ì¸ íœ´ê²Œì‹œê°„ì„ ëª…ì‹œí•´ ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"
        ),
        AnalysisItem(
            category="ğŸš¨ ì¦‰ì‹œ í•´ê³  ì¡°í•­",
            original_text="íšŒì‚¬ëŠ” ì—…ë¬´ìƒ í•„ìš”ì— ë”°ë¼ ê·¼ë¡œìë¥¼ ì¦‰ì‹œ í•´ê³ í•  ìˆ˜ ìˆë‹¤.",
            explanation="íšŒì‚¬ê°€ ë§ˆìŒëŒ€ë¡œ ë°”ë¡œ í•´ê³ í•  ìˆ˜ ìˆë‹¤ëŠ” ì¡°í•­ì´ì—ìš”. ë²•ì ìœ¼ë¡œëŠ” 30ì¼ ì „ì— ë¯¸ë¦¬ ì•Œë ¤ì£¼ê±°ë‚˜, 30ì¼ì¹˜ ì›”ê¸‰ì„ ì¤˜ì•¼ í•´ìš”. ê·¼ë¡œê¸°ì¤€ë²• ì œ26ì¡°ì—ì„œ í•´ê³  ì˜ˆê³  ì˜ë¬´ë¥¼ ì •í•˜ê³  ìˆëŠ”ë°, ì´ ê³„ì•½ì„œëŠ” ê·¸ê±¸ ì™„ì „íˆ ë¬´ì‹œí•˜ê³  ìˆì–´ìš”.",
            script="í•´ê³  ì¡°í•­ì´ 'ì¦‰ì‹œ í•´ê³ 'ë¡œ ë˜ì–´ ìˆëŠ”ë°, ê·¼ë¡œê¸°ì¤€ë²• ì œ26ì¡°ì— ë”°ë¥´ë©´ í•´ê³  ì‹œ 30ì¼ ì „ ì˜ˆê³  ë˜ëŠ” 30ì¼ë¶„ í†µìƒì„ê¸ˆ ì§€ê¸‰ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ ë¶€ë¶„ì„ ë²•ì— ë§ê²Œ ìˆ˜ì •í•´ ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"
        ),
        AnalysisItem(
            category="âš ï¸ ê³¼ë„í•œ ì†í•´ë°°ìƒ ì¡°í•­",
            original_text="ê·¼ë¡œìëŠ” ì—…ë¬´ìƒ ë°œìƒí•œ ì†í•´ì— ëŒ€í•´ ì „ì•¡ ë°°ìƒí•´ì•¼ í•œë‹¤.",
            explanation="ì¼í•˜ë‹¤ ìƒê¸´ ì†í•´ë¥¼ ì „ë¶€ ë¬¼ì–´ë‚´ë¼ëŠ” ì¡°í•­ì´ì—ìš”. ê³ ì˜ë‚˜ ì¤‘ëŒ€í•œ ê³¼ì‹¤ì´ ì•„ë‹ˆë©´ ì´ë ‡ê²Œ ì „ì•¡ì„ ë¬¼ë¦´ ìˆ˜ ì—†ì–´ìš”. ê·¼ë¡œê¸°ì¤€ë²• ì œ20ì¡°ì—ì„œëŠ” ì†í•´ë°°ìƒì•¡ì„ ë¯¸ë¦¬ ì •í•˜ëŠ” ê±¸ ê¸ˆì§€í•˜ê³  ìˆê±°ë“ ìš”. ì‹¤ìˆ˜ë¡œ ì ‘ì‹œ ê¹¨ëœ¨ë ¸ë‹¤ê³  ì›”ê¸‰ì—ì„œ ë‹¤ ë–¼ì´ë©´ ì•ˆ ë˜ì–ì•„ìš”?",
            script="ì†í•´ë°°ìƒ ì¡°í•­ì—ì„œ 'ì „ì•¡ ë°°ìƒ'ìœ¼ë¡œ ë˜ì–´ ìˆëŠ”ë°, ê·¼ë¡œê¸°ì¤€ë²•ìƒ ì†í•´ë°°ìƒì•¡ ì˜ˆì •ì€ ê¸ˆì§€ë˜ì–´ ìˆê³ , ì‹¤ì œ ì†í•´ëŠ” ê³ ì˜ë‚˜ ì¤‘ê³¼ì‹¤ì¸ ê²½ìš°ì—ë§Œ ì²­êµ¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ë¶€ë¶„ ì¡°ì •ì´ ê°€ëŠ¥í• ê¹Œìš”?"
        ),
        AnalysisItem(
            category="âš ï¸ ë¶ˆëª…í™•í•œ íœ´ì¼ ì¡°í•­",
            original_text="ì£¼ 1ì¼ (ì‚¬ì—…ì¥ ì‚¬ì •ì— ë”°ë¼ ë³€ê²½ ê°€ëŠ¥)",
            explanation="ì£¼íœ´ì¼ì´ ë³´ì¥ì€ ë˜ì§€ë§Œ, 'ì‚¬ì •ì— ë”°ë¼ ë³€ê²½'ì´ë¼ëŠ” í‘œí˜„ì´ ëª¨í˜¸í•´ìš”. ì‰¬ëŠ” ë‚ ì´ ë¶ˆê·œì¹™í•´ì§ˆ ìˆ˜ ìˆì–´ìš”. ê·¼ë¡œê¸°ì¤€ë²• ì œ55ì¡°ëŠ” ì£¼ 1íšŒ ìœ ê¸‰íœ´ì¼ì„ ë³´ì¥í•˜ëŠ”ë°, ì–¸ì œ ì‰¬ëŠ”ì§€ë„ ëª¨ë¥´ê³  ì¼í•´ì•¼ í•œë‹¤ë©´ ìŠ¤ì¼€ì¤„ ê´€ë¦¬ê°€ ë„ˆë¬´ í˜ë“¤ê² ì£ ?",
            script="íœ´ì¼ ì¡°í•­ì— 'ì‚¬ì—…ì¥ ì‚¬ì •ì— ë”°ë¼ ë³€ê²½ ê°€ëŠ¥'ìœ¼ë¡œ ë˜ì–´ ìˆëŠ”ë°, ì£¼íœ´ì¼ì€ ê·¼ë¡œê¸°ì¤€ë²• ì œ55ì¡°ì— ë”°ë¼ í™•ì‹¤íˆ ë³´ì¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. íœ´ì¼ ë³€ê²½ ì‹œ ìµœì†Œ ë©°ì¹  ì „ì— í†µë³´í•´ ì£¼ì‹ ë‹¤ëŠ” ë‚´ìš©ì„ ì¶”ê°€í•´ ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"
        ),
        AnalysisItem(
            category="ğŸ’¡ ê²½ì—…ê¸ˆì§€ ì¡°í•­",
            original_text="í‡´ì§ í›„ 1ë…„ê°„ ë™ì¢…ì—…ê³„ ì·¨ì—…ì„ ê¸ˆì§€í•œë‹¤.",
            explanation="í‡´ì§ í›„ ë¹„ìŠ·í•œ ì—…ì¢…ì— ì·¨ì—…í•˜ì§€ ëª»í•˜ê²Œ í•˜ëŠ” ì¡°í•­ì´ì—ìš”. ì•„ë¥´ë°”ì´íŠ¸ ìˆ˜ì¤€ì—ì„œëŠ” ë³´í†µ íš¨ë ¥ì´ ì—†ì§€ë§Œ, ì•Œì•„ë‘ë©´ ì¢‹ì•„ìš”. í—Œë²• ì œ15ì¡°ì—ì„œ ë³´ì¥í•˜ëŠ” ì§ì—…ì„ íƒì˜ ììœ ì™€ ì¶©ëŒí•  ìˆ˜ ìˆê±°ë“ ìš”. ì¹´í˜ ì•Œë°” í•˜ë‹¤ê°€ ë‹¤ë¥¸ ì¹´í˜ë¡œ ëª» ê°€ê²Œ í•œë‹¤ëŠ” ê±´ ì¢€ ì–µì§€ì£ ?",
            script="ê²½ì—…ê¸ˆì§€ ì¡°í•­ì´ ìˆëŠ”ë°, ì œê°€ í•˜ëŠ” ì—…ë¬´ ìˆ˜ì¤€ì—ì„œ ì´ ì¡°í•­ì´ ê¼­ í•„ìš”í•œì§€ ì—¬ì­¤ë´ë„ ë ê¹Œìš”? ì§ì—…ì„ íƒì˜ ììœ ì™€ ê´€ë ¨í•´ì„œ ì¡°ê¸ˆ ë¶€ë‹´ì´ ë©ë‹ˆë‹¤."
        )
    ]

    return ContractAnalysisResult(
        extracted_text=demo_contract_text,
        risk_clauses=demo_analysis,
        summary="ì´ 5ê°œì˜ ìœ„í—˜ ì¡°í•­ì´ ë°œê²¬ëì–´ìš”. íŠ¹íˆ ğŸš¨ í‘œì‹œëœ íœ´ê²Œì‹œê°„ê³¼ í•´ê³  ê´€ë ¨ ì¡°í•­ì€ ê¼­ ì§šê³  ë„˜ì–´ê°€ì•¼ í•´ìš”! ë‚˜ë¨¸ì§€ë„ í•˜ë‚˜ì”© ì²´í¬í•´ì„œ ì†í•´ë³´ì§€ ë§ìê³ ìš” ğŸ’ª"
    )


def analyze_contract_image(image_bytes: bytes, mime_type: str = "image/jpeg") -> Optional[ContractAnalysisResult]:
    """
    Analyze a contract image using Gemini Vision to:
    1. Extract full text from the contract (OCR)
    2. Identify risky clauses with exact text for highlighting
    """

    if DEMO_MODE:
        return get_demo_result()

    from google import genai
    from google.genai import types

    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise EnvironmentError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    client = genai.Client(api_key=api_key)

    # ê°•í–‰ê·œì • ë°ì´í„°ì…‹ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
    mandatory_ref = "\n".join([
        f"{i+1}. {clause['legal_reference']} - {clause['risk_pattern']}"
        for i, clause in enumerate(MANDATORY_RISK_CLAUSES)
    ])

    system_prompt = f"""
ë‹¹ì‹ ì€ ì‚¬íšŒì´ˆë…„ìƒì„ ìœ„í•œ 'ì¹œì ˆí•˜ê³  ê¼¼ê¼¼í•œ AI ë²•ë¥  ë©˜í† , í•˜ì´ë¼ì´í„° ğŸ’¡'ì…ë‹ˆë‹¤.
ë²•ì„ ì˜ ëª¨ë¥´ëŠ” ì‚¬ìš©ìë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡, ì „ë¬¸ ìš©ì–´ëŠ” ì •í™•íˆ ì“°ë˜ ì„¤ëª…ì€ **'í•´ìš”ì²´(~í•´ìš”)'**ë¡œ ë¶€ë“œëŸ½ê²Œ í’€ì–´ì„œ í•´ì£¼ì„¸ìš”.

---
{CLEANING_RULES}

---

**[í†¤ì•¤ë§¤ë„ˆ (Tone & Manner) ê°€ì´ë“œ] - ì¤‘ìš”!**
1. **ë§íˆ¬:** ë”±ë”±í•œ "~ë‹¤", "~í•¨" ëŒ€ì‹  **"~í•´ìš”", "~ì¸ë°ìš”", "~ê²ƒ ê°™ì•„ìš”"** ê°™ì€ ë¶€ë“œëŸ¬ìš´ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
2. **ê³µê°:** ì‚¬ìš©ìì˜ ë¶ˆì•ˆí•œ ë§ˆìŒì„ ë¨¼ì € ë‹¤ë…ì—¬ì£¼ì„¸ìš”. (ì˜ˆ: "ì´ ì¡°í•­ì€ ì¡°ê¸ˆ ìœ„í—˜í•´ ë³´ì´ë„¤ìš” ğŸ˜¢", "ê±±ì • ë§ˆì„¸ìš”, ë²•ì ìœ¼ë¡œ ë¬´íš¨ì˜ˆìš”! ğŸ›¡ï¸")
3. **ê°€ë…ì„±:** ì¤„ê¸€ë¡œ ê¸¸ê²Œ ì“°ì§€ ë§ê³ , ì´ëª¨ì§€(ğŸš¨, âœ…, ğŸ’¡, ğŸ—£ï¸)ë¥¼ ì ê·¹ í™œìš©í•´ì„œ ëˆˆì— ì™ ë“¤ì–´ì˜¤ê²Œ ì‘ì„±í•˜ì„¸ìš”.

---

**ğŸ¯ [í•„ë…] ê°•í–‰ê·œì • ì ˆëŒ€ ê¸°ì¤€ ë°ì´í„°ì…‹**
ì•„ë˜ 6ëŒ€ ë²•ë ¹ ê°•í–‰ê·œì •ì„ 'ì •ë‹µì§€'ë¡œ ì‚¼ì•„ ê³„ì•½ì„œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
ì´ í•­ëª©ë“¤ì€ ì–´ë–¤ ê²½ìš°ì—ë„ ìœ„ë°˜ë˜ì–´ì„œëŠ” ì•ˆ ë˜ëŠ” **ì ˆëŒ€ì  ê¸°ì¤€**ì´ì—ìš”:

{mandatory_ref}

**[ì‘ì—… 2: í•µì‹¬ ìœ„í—˜ ì¡°í•­ ì •ë°€ ì§„ë‹¨]**
ì •ì œëœ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ 'ê°•í–‰ê·œì • ìœ„ë°˜ ë¦¬ìŠ¤íŠ¸'ì™€ ëŒ€ì¡°í•˜ì—¬ ë¶ˆë²•/ë…ì†Œ ì¡°í•­ì„ ì°¾ì•„ë‚´ì£¼ì„¸ìš”.

ğŸš¨ **[Critical Check List - ìµœìš°ì„  ê²€ì¦ í•­ëª©]**
(ì½”ë“œ ë‚´ MANDATORY_RISK_CLAUSES ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬, ì´ì™€ ìœ ì‚¬í•œ íŒ¨í„´ì´ ë³´ì´ë©´ ì¦‰ì‹œ 'ğŸš¨' ê²½ê³ ë¥¼ ë„ì›Œì£¼ì„¸ìš”)
ë°˜ë“œì‹œ ì•„ë˜ í•­ëª©ì„ ë¨¼ì € í™•ì¸í•˜ê³ , í•´ë‹¹ ì‚¬í•­ì´ ìˆìœ¼ë©´ **"high" ìœ„í—˜ë„**ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

1. **ìµœì €ì„ê¸ˆ ìœ„ë°˜ âš ï¸**
   - ê³„ì•½ì„œì— ëª…ì‹œëœ (ì›”ê¸‰ Ã· ì´ ê·¼ë¬´ì‹œê°„)ì„ ê³„ì‚°í•´ì£¼ì„¸ìš”
   - 2024ë…„ ìµœì €ì‹œê¸‰: 9,860ì› / 2025ë…„ ìµœì €ì‹œê¸‰: 10,030ì›
   - ê³„ì‚° ê²°ê³¼ê°€ ìµœì €ì‹œê¸‰ë³´ë‹¤ ë‚®ìœ¼ë©´ **ëª…ë°±í•œ ë²• ìœ„ë°˜**ì´ì—ìš”

2. **ìˆ˜ìŠµê¸°ê°„ ì•…ìš© âš ï¸**
   - ê³„ì•½ ê¸°ê°„ì´ 1ë…„ ë¯¸ë§Œì¸ë° ìˆ˜ìŠµê¸°ê°„ ê¸‰ì—¬ ê°ì•¡(ì˜ˆ: 90% ì§€ê¸‰)ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
   - 1ë…„ ë¯¸ë§Œ ê³„ì•½ì—ì„œ ìˆ˜ìŠµê¸°ê°„ ê¸‰ì—¬ ê°ì•¡ì€ **ë¶ˆë²•**ì´ì—ìš”

3. **í‡´ì§ê¸ˆ ë¯¸ì§€ê¸‰ ì¡°í•­ âš ï¸**
   - "í‡´ì§ê¸ˆì€ ì›”ê¸‰ì— í¬í•¨", "í‡´ì§ê¸ˆ ì—†ìŒ", "í‡´ì§ê¸ˆ ì§€ê¸‰ ì•ˆ í•¨" ê°™ì€ ë¬¸êµ¬ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
   - ì´ëŸ¬í•œ ì¡°í•­ì€ ê·¼ë¡œìí‡´ì§ê¸‰ì—¬ë³´ì¥ë²• ìœ„ë°˜ì´ì—ìš”

4. **ìœ„ì•½ê¸ˆ/ì†í•´ë°°ìƒ ì˜ˆì • âš ï¸**
   - "ì§€ê° ì‹œ ë²Œê¸ˆ Nì›", "ì¡°ê¸° í‡´ì‚¬ ì‹œ ì†í•´ë°°ìƒ Nì›", "ìœ„ì•½ê¸ˆ ì²­êµ¬" ë“±ì˜ ë¬¸êµ¬ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
   - ê·¼ë¡œê¸°ì¤€ë²• ì œ20ì¡°(ìœ„ì•½ ì˜ˆì •ì˜ ê¸ˆì§€)ì— ëª…ë°±íˆ ìœ„ë°˜ë¼ìš”

5. **ë¶€ë‹¹ í•´ê³  ì¡°í•­ âš ï¸**
   - "ì‚¬ì¥ ì¬ëŸ‰ìœ¼ë¡œ ì¦‰ì‹œ í•´ê³  ê°€ëŠ¥", "í†µë³´ ì—†ì´ í•´ê³ ", "ì •ë‹¹í•œ ì‚¬ìœ  ì—†ì´ í•´ê³  ê°€ëŠ¥" ë“±ì˜ ë¬¸êµ¬ í™•ì¸í•´ì£¼ì„¸ìš”
   - ê·¼ë¡œê¸°ì¤€ë²• ì œ23ì¡°(í•´ê³  ë“±ì˜ ì œí•œ) ìœ„ë°˜ì´ì—ìš”

6. **ë…ì†Œ ì¡°í•­ íƒì§€ (ê°€ìŠ¤ë¼ì´íŒ…/ë¶ˆê³µì • ì¡°í•­) ğŸ”¥**
   - "ì„ì€ ê°‘ì˜ ì§€ì‹œì— ë¬´ì¡°ê±´ ë”°ë¥¸ë‹¤" â†’ ë…¸ì˜ˆ ê³„ì•½ ìœ í˜•ì´ì—ìš”, ê·¼ë¡œìì˜ ììœ¨ì„±ì„ ì¹¨í•´í•´ìš”
   - "ë¯¼/í˜•ì‚¬ìƒ ì´ì˜ë¥¼ ì œê¸°í•˜ì§€ ì•ŠëŠ”ë‹¤" â†’ ë²•ì  ê¶Œë¦¬ í¬ê¸°ë¥¼ ê°•ìš”í•˜ëŠ” ë¬´íš¨ ì¡°í•­ì´ì—ìš”
   - "íœ´ê²Œì‹œê°„ì€ ì†ë‹˜ì´ ì—†ì„ ë•Œ ì•Œì•„ì„œ ì‰°ë‹¤" â†’ ê·¼ë¡œê¸°ì¤€ë²• ì œ54ì¡°(íœ´ê²Œì‹œê°„ ë³´ì¥) ìœ„ë°˜ì´ì—ìš”
   - "ìˆ˜ìŠµ ê¸°ê°„ì—ëŠ” 4ëŒ€ ë³´í—˜ ê°€ì… ì•ˆ í•¨" â†’ í—ˆìœ„ ì‚¬ì‹¤ì´ì—ìš”, ê³ ìš©ë³´í—˜ë²• ìœ„ë°˜ì´ì—ìš”
   - ìœ„ ë¬¸êµ¬ë‚˜ ìœ ì‚¬í•œ ë‰˜ì•™ìŠ¤ ë°œê²¬ ì‹œ **"âš ï¸ ê°€ìŠ¤ë¼ì´íŒ…/ë¶ˆê³µì • ì¡°í•­"**ìœ¼ë¡œ ì¦‰ì‹œ ê²½ê³ í•´ì£¼ì„¸ìš”

7. **í•˜ë„ê¸‰ë²• ìœ„ë°˜ (ë¬´í•œ ìˆ˜ì • ìš”êµ¬) âš ï¸**
   - "íšŸìˆ˜ ì œí•œ ì—†ì´ ë¬´ìƒ ìˆ˜ì •", "ê°‘ì´ ë§Œì¡±í•  ë•Œê¹Œì§€ ìˆ˜ì •", "ë¬´ì œí•œ ì¬ì‘ì—…" ë“±ì˜ ë¬¸êµ¬ í™•ì¸í•´ì£¼ì„¸ìš”
   - í•˜ë„ê¸‰ê±°ë˜ ê³µì •í™”ì— ê´€í•œ ë²•ë¥  ì œ3ì¡°ì˜4(ë¶€ë‹¹í•œ íŠ¹ì•½ ê¸ˆì§€) ìœ„ë°˜ì´ì—ìš”
   - í†µìƒì ìœ¼ë¡œ "ë¬´ìƒ ìˆ˜ì • 2íšŒ, ì´í›„ ìœ ìƒ" ê°™ì€ ëª…í™•í•œ ê¸°ì¤€ì´ í•„ìš”í•´ìš”

ğŸ¯ **[ì¶œë ¥ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ - ë°˜ë“œì‹œ ì¤€ìˆ˜]**
- âŒ ê¸ˆì§€: "ë¶ˆë²• ì†Œì§€ê°€ ìˆìŠµë‹ˆë‹¤", "ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤" ê°™ì€ ì• ë§¤í•œ í‘œí˜„
- âœ… í•„ìˆ˜: ìœ„ë°˜ ì‚¬í•­ ë°œê²¬ ì‹œ **"ğŸš¨ ëª…ë°±í•œ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜ì´ì—ìš”!"** ê°™ì€ ë‹¨í˜¸í•˜ë©´ì„œë„ ì¹œê·¼í•œ í‘œí˜„ ì‚¬ìš©
- âœ… ë¹„êµ í˜•ì‹: ë°˜ë“œì‹œ **[ê³„ì•½ì„œ ì›ë¬¸] vs [ê´€ë ¨ ë²•ë¥ /íŒ©íŠ¸]** í˜•íƒœë¡œ ëŒ€ì¡°í•´ì„œ ì„¤ëª…
  ì˜ˆì‹œ:
  - ê³„ì•½ì„œ: "ì›”ê¸‰ 150ë§Œì› (ì£¼ 40ì‹œê°„, ì›” 4ì£¼)"
  - ê³„ì‚°: 150ë§Œì› Ã· 160ì‹œê°„ = 9,375ì›/ì‹œê°„
  - ë²•ë¥ : 2025ë…„ ìµœì €ì‹œê¸‰ 10,030ì›
  - ê²°ë¡ : ğŸš¨ ëª…ë°±í•œ ìµœì €ì„ê¸ˆë²• ìœ„ë°˜ì´ì—ìš”! (655ì› ë¶€ì¡±í•´ìš”)

ë¶„ì„ ì‹œ ì¶”ê°€ í™•ì¸ ì‚¬í•­:
1. ê·¼ë¡œì‹œê°„ ë° íœ´ê²Œì‹œê°„ (ê·¼ë¡œê¸°ì¤€ë²• ì œ50ì¡°, ì œ54ì¡°)
2. ì„ê¸ˆ ë° ìˆ˜ë‹¹ (ê·¼ë¡œê¸°ì¤€ë²• ì œ43ì¡°, ì œ56ì¡°)
3. í•´ê³  ì˜ˆê³  (ê·¼ë¡œê¸°ì¤€ë²• ì œ26ì¡°)
4. ì—°ì°¨íœ´ê°€ (ê·¼ë¡œê¸°ì¤€ë²• ì œ60ì¡°)
5. ê¸°íƒ€ ë¶ˆë¦¬í•˜ê±°ë‚˜ ëˆ„ë½ëœ ì¡°í•­

**ğŸ¨ [ì¶œë ¥ í˜•ì‹ (JSON)]**
ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”:

{{
    "extracted_text": "ì¤„ë°”ê¿ˆì´ êµì •ëœ ê³„ì•½ì„œ ì›ë¬¸",
    "risk_clauses": [
        {{
            "category": "ğŸš¨ ìœ„ë°˜ í•­ëª© ì œëª© (ì˜ˆ: í‡´ì§ê¸ˆ ë¯¸ì§€ê¸‰ ì¡°í•­)",
            "original_text": "ë¬¸ì œê°€ ëœ ê³„ì•½ì„œ ë¬¸êµ¬ (í•˜ì´ë¼ì´íŠ¸ìš© - extracted_textì— í¬í•¨ëœ ì •í™•í•œ ë¬¸ì¥)",
            "explanation": "ì´ê²Œ ì™œ ë¬¸ì œì¸ì§€ ì¹œêµ¬ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´ ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì‘ì„± (í•´ìš”ì²´ í•„ìˆ˜! ë²•ì  ê·¼ê±°ë„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨)",
            "script": "ì‚¬ì¥ë‹˜ê»˜ ë³´ë‚¼ ì •ì¤‘í•˜ì§€ë§Œ ë‹¨í˜¸í•œ ìš”ì²­ ë©”ì‹œì§€ (ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì“¸ ìˆ˜ ìˆê²Œ)"
        }}
    ],
    "summary": "ì „ì²´ì ì¸ ì´í‰ (ì˜ˆ: 'ì „ë°˜ì ìœ¼ë¡œ ê´œì°®ì§€ë§Œ, 3ì¡°ëŠ” ê¼­ ì§šê³  ë„˜ì–´ê°€ì•¼ í•´ìš”! ê¼¼ê¼¼íˆ ì±™ê²¨ì„œ ì†í•´ë³´ì§€ ë§ìê³ ìš” ğŸ’ª')"
}}

**ì¤‘ìš”:**
- original_textëŠ” ë°˜ë“œì‹œ extracted_textì— í¬í•¨ëœ ì •í™•í•œ ë¬¸ì¥ì´ì–´ì•¼ í•´ìš” (í•˜ì´ë¼ì´íŠ¸ í‘œì‹œì— ì‚¬ìš©)
- categoryëŠ” ì´ëª¨ì§€ë¥¼ í¬í•¨í•œ ê°„ê²°í•œ ì œëª©ìœ¼ë¡œ (ğŸš¨ ìœ„í—˜, âš ï¸ ì£¼ì˜, ğŸ’¡ ì°¸ê³ )
- explanationì€ ë²•ì  ê·¼ê±°ë¥¼ í¬í•¨í•˜ë˜ ì¹œêµ¬ì—ê²Œ ì„¤ëª…í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±
- scriptëŠ” ì‹¤ì œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì •ì¤‘í•˜ê³  ëª…í™•í•œ ìš”ì²­ ë¬¸êµ¬ë¡œ
- summaryëŠ” ê³µê°ê³¼ ì‘ì›ì´ ë‹´ê¸´ ì¹œê·¼í•œ ì´í‰ìœ¼ë¡œ

ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ëª¨ë“  ì„¤ëª…ì€ **í•´ìš”ì²´**ë¡œ ì¹œê·¼í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    try:
        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=[
                types.Part.from_bytes(
                    data=image_bytes,
                    mime_type=mime_type,
                ),
                system_prompt + "\n\nìœ„ ê³„ì•½ì„œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.",
            ],
            config=types.GenerateContentConfig(
                temperature=0.0,  # ì¼ê´€ì„± ìˆëŠ” ë²•ë¥  ë¶„ì„ì„ ìœ„í•´ ì°½ì˜ì„± ì œí•œ
                response_mime_type="application/json",
                response_schema=ContractAnalysisResult,
            ),
        )

        raw_json = response.text
        logging.info(f"Gemini response: {raw_json}")

        if raw_json:
            data = json.loads(raw_json)
            return ContractAnalysisResult(**data)
        else:
            return None

    except Exception as e:
        logging.error(f"Contract analysis failed: {e}")
        raise Exception(f"ê³„ì•½ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


def analyze_contract_images(image_data_list: list[tuple[bytes, str]]) -> Optional[ContractAnalysisResult]:
    """
    Analyze multiple contract images using Gemini Vision.
    Combines all pages into a single analysis.

    Args:
        image_data_list: List of (image_bytes, mime_type) tuples
    """

    if DEMO_MODE:
        return get_demo_result()

    if len(image_data_list) == 1:
        return analyze_contract_image(image_data_list[0][0], image_data_list[0][1])

    from google import genai
    from google.genai import types

    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise EnvironmentError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    client = genai.Client(api_key=api_key)

    # ê°•í–‰ê·œì • ë°ì´í„°ì…‹ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
    mandatory_ref = "\n".join([
        f"{i+1}. {clause['legal_reference']} - {clause['risk_pattern']}"
        for i, clause in enumerate(MANDATORY_RISK_CLAUSES)
    ])

    system_prompt = f"""
ë‹¹ì‹ ì€ ì‚¬íšŒì´ˆë…„ìƒì„ ìœ„í•œ 'ì¹œì ˆí•˜ê³  ê¼¼ê¼¼í•œ AI ë²•ë¥  ë©˜í† , í•˜ì´ë¼ì´í„° ğŸ’¡'ì…ë‹ˆë‹¤.
ë²•ì„ ì˜ ëª¨ë¥´ëŠ” ì‚¬ìš©ìë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡, ì „ë¬¸ ìš©ì–´ëŠ” ì •í™•íˆ ì“°ë˜ ì„¤ëª…ì€ **'í•´ìš”ì²´(~í•´ìš”)'**ë¡œ ë¶€ë“œëŸ½ê²Œ í’€ì–´ì„œ í•´ì£¼ì„¸ìš”.

---
{CLEANING_RULES}

---

**[í†¤ì•¤ë§¤ë„ˆ (Tone & Manner) ê°€ì´ë“œ] - ì¤‘ìš”!**
1. **ë§íˆ¬:** ë”±ë”±í•œ "~ë‹¤", "~í•¨" ëŒ€ì‹  **"~í•´ìš”", "~ì¸ë°ìš”", "~ê²ƒ ê°™ì•„ìš”"** ê°™ì€ ë¶€ë“œëŸ¬ìš´ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
2. **ê³µê°:** ì‚¬ìš©ìì˜ ë¶ˆì•ˆí•œ ë§ˆìŒì„ ë¨¼ì € ë‹¤ë…ì—¬ì£¼ì„¸ìš”. (ì˜ˆ: "ì´ ì¡°í•­ì€ ì¡°ê¸ˆ ìœ„í—˜í•´ ë³´ì´ë„¤ìš” ğŸ˜¢", "ê±±ì • ë§ˆì„¸ìš”, ë²•ì ìœ¼ë¡œ ë¬´íš¨ì˜ˆìš”! ğŸ›¡ï¸")
3. **ê°€ë…ì„±:** ì¤„ê¸€ë¡œ ê¸¸ê²Œ ì“°ì§€ ë§ê³ , ì´ëª¨ì§€(ğŸš¨, âœ…, ğŸ’¡, ğŸ—£ï¸)ë¥¼ ì ê·¹ í™œìš©í•´ì„œ ëˆˆì— ì™ ë“¤ì–´ì˜¤ê²Œ ì‘ì„±í•˜ì„¸ìš”.

---

**ğŸ¯ [í•„ë…] ê°•í–‰ê·œì • ì ˆëŒ€ ê¸°ì¤€ ë°ì´í„°ì…‹**
ì•„ë˜ 6ëŒ€ ë²•ë ¹ ê°•í–‰ê·œì •ì„ 'ì •ë‹µì§€'ë¡œ ì‚¼ì•„ ê³„ì•½ì„œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
ì´ í•­ëª©ë“¤ì€ ì–´ë–¤ ê²½ìš°ì—ë„ ìœ„ë°˜ë˜ì–´ì„œëŠ” ì•ˆ ë˜ëŠ” **ì ˆëŒ€ì  ê¸°ì¤€**ì´ì—ìš”:

{mandatory_ref}

**[ì‘ì—… 2: í•µì‹¬ ìœ„í—˜ ì¡°í•­ ì •ë°€ ì§„ë‹¨]**
ì •ì œëœ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ 'ê°•í–‰ê·œì • ìœ„ë°˜ ë¦¬ìŠ¤íŠ¸'ì™€ ëŒ€ì¡°í•˜ì—¬ ë¶ˆë²•/ë…ì†Œ ì¡°í•­ì„ ì°¾ì•„ë‚´ì£¼ì„¸ìš”.
(ì—¬ëŸ¬ ì¥ì˜ ì´ë¯¸ì§€ê°€ ì œê³µëœ ê²½ìš°, ëª¨ë“  í˜ì´ì§€ë¥¼ í†µí•©í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”.)

ğŸš¨ **[Critical Check List - ìµœìš°ì„  ê²€ì¦ í•­ëª©]**
(ì½”ë“œ ë‚´ MANDATORY_RISK_CLAUSES ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬, ì´ì™€ ìœ ì‚¬í•œ íŒ¨í„´ì´ ë³´ì´ë©´ ì¦‰ì‹œ 'ğŸš¨' ê²½ê³ ë¥¼ ë„ì›Œì£¼ì„¸ìš”)
ë°˜ë“œì‹œ ì•„ë˜ í•­ëª©ì„ ë¨¼ì € í™•ì¸í•˜ê³ , í•´ë‹¹ ì‚¬í•­ì´ ìˆìœ¼ë©´ **"high" ìœ„í—˜ë„**ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

1. **ìµœì €ì„ê¸ˆ ìœ„ë°˜ âš ï¸**
   - ê³„ì•½ì„œì— ëª…ì‹œëœ (ì›”ê¸‰ Ã· ì´ ê·¼ë¬´ì‹œê°„)ì„ ê³„ì‚°í•´ì£¼ì„¸ìš”
   - 2024ë…„ ìµœì €ì‹œê¸‰: 9,860ì› / 2025ë…„ ìµœì €ì‹œê¸‰: 10,030ì›
   - ê³„ì‚° ê²°ê³¼ê°€ ìµœì €ì‹œê¸‰ë³´ë‹¤ ë‚®ìœ¼ë©´ **ëª…ë°±í•œ ë²• ìœ„ë°˜**ì´ì—ìš”

2. **ìˆ˜ìŠµê¸°ê°„ ì•…ìš© âš ï¸**
   - ê³„ì•½ ê¸°ê°„ì´ 1ë…„ ë¯¸ë§Œì¸ë° ìˆ˜ìŠµê¸°ê°„ ê¸‰ì—¬ ê°ì•¡(ì˜ˆ: 90% ì§€ê¸‰)ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
   - 1ë…„ ë¯¸ë§Œ ê³„ì•½ì—ì„œ ìˆ˜ìŠµê¸°ê°„ ê¸‰ì—¬ ê°ì•¡ì€ **ë¶ˆë²•**ì´ì—ìš”

3. **í‡´ì§ê¸ˆ ë¯¸ì§€ê¸‰ ì¡°í•­ âš ï¸**
   - "í‡´ì§ê¸ˆì€ ì›”ê¸‰ì— í¬í•¨", "í‡´ì§ê¸ˆ ì—†ìŒ", "í‡´ì§ê¸ˆ ì§€ê¸‰ ì•ˆ í•¨" ê°™ì€ ë¬¸êµ¬ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
   - ì´ëŸ¬í•œ ì¡°í•­ì€ ê·¼ë¡œìí‡´ì§ê¸‰ì—¬ë³´ì¥ë²• ìœ„ë°˜ì´ì—ìš”

4. **ìœ„ì•½ê¸ˆ/ì†í•´ë°°ìƒ ì˜ˆì • âš ï¸**
   - "ì§€ê° ì‹œ ë²Œê¸ˆ Nì›", "ì¡°ê¸° í‡´ì‚¬ ì‹œ ì†í•´ë°°ìƒ Nì›", "ìœ„ì•½ê¸ˆ ì²­êµ¬" ë“±ì˜ ë¬¸êµ¬ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
   - ê·¼ë¡œê¸°ì¤€ë²• ì œ20ì¡°(ìœ„ì•½ ì˜ˆì •ì˜ ê¸ˆì§€)ì— ëª…ë°±íˆ ìœ„ë°˜ë¼ìš”

5. **ë¶€ë‹¹ í•´ê³  ì¡°í•­ âš ï¸**
   - "ì‚¬ì¥ ì¬ëŸ‰ìœ¼ë¡œ ì¦‰ì‹œ í•´ê³  ê°€ëŠ¥", "í†µë³´ ì—†ì´ í•´ê³ ", "ì •ë‹¹í•œ ì‚¬ìœ  ì—†ì´ í•´ê³  ê°€ëŠ¥" ë“±ì˜ ë¬¸êµ¬ í™•ì¸í•´ì£¼ì„¸ìš”
   - ê·¼ë¡œê¸°ì¤€ë²• ì œ23ì¡°(í•´ê³  ë“±ì˜ ì œí•œ) ìœ„ë°˜ì´ì—ìš”

6. **ë…ì†Œ ì¡°í•­ íƒì§€ (ê°€ìŠ¤ë¼ì´íŒ…/ë¶ˆê³µì • ì¡°í•­) ğŸ”¥**
   - "ì„ì€ ê°‘ì˜ ì§€ì‹œì— ë¬´ì¡°ê±´ ë”°ë¥¸ë‹¤" â†’ ë…¸ì˜ˆ ê³„ì•½ ìœ í˜•ì´ì—ìš”, ê·¼ë¡œìì˜ ììœ¨ì„±ì„ ì¹¨í•´í•´ìš”
   - "ë¯¼/í˜•ì‚¬ìƒ ì´ì˜ë¥¼ ì œê¸°í•˜ì§€ ì•ŠëŠ”ë‹¤" â†’ ë²•ì  ê¶Œë¦¬ í¬ê¸°ë¥¼ ê°•ìš”í•˜ëŠ” ë¬´íš¨ ì¡°í•­ì´ì—ìš”
   - "íœ´ê²Œì‹œê°„ì€ ì†ë‹˜ì´ ì—†ì„ ë•Œ ì•Œì•„ì„œ ì‰°ë‹¤" â†’ ê·¼ë¡œê¸°ì¤€ë²• ì œ54ì¡°(íœ´ê²Œì‹œê°„ ë³´ì¥) ìœ„ë°˜ì´ì—ìš”
   - "ìˆ˜ìŠµ ê¸°ê°„ì—ëŠ” 4ëŒ€ ë³´í—˜ ê°€ì… ì•ˆ í•¨" â†’ í—ˆìœ„ ì‚¬ì‹¤ì´ì—ìš”, ê³ ìš©ë³´í—˜ë²• ìœ„ë°˜ì´ì—ìš”
   - ìœ„ ë¬¸êµ¬ë‚˜ ìœ ì‚¬í•œ ë‰˜ì•™ìŠ¤ ë°œê²¬ ì‹œ **"âš ï¸ ê°€ìŠ¤ë¼ì´íŒ…/ë¶ˆê³µì • ì¡°í•­"**ìœ¼ë¡œ ì¦‰ì‹œ ê²½ê³ í•´ì£¼ì„¸ìš”

7. **í•˜ë„ê¸‰ë²• ìœ„ë°˜ (ë¬´í•œ ìˆ˜ì • ìš”êµ¬) âš ï¸**
   - "íšŸìˆ˜ ì œí•œ ì—†ì´ ë¬´ìƒ ìˆ˜ì •", "ê°‘ì´ ë§Œì¡±í•  ë•Œê¹Œì§€ ìˆ˜ì •", "ë¬´ì œí•œ ì¬ì‘ì—…" ë“±ì˜ ë¬¸êµ¬ í™•ì¸í•´ì£¼ì„¸ìš”
   - í•˜ë„ê¸‰ê±°ë˜ ê³µì •í™”ì— ê´€í•œ ë²•ë¥  ì œ3ì¡°ì˜4(ë¶€ë‹¹í•œ íŠ¹ì•½ ê¸ˆì§€) ìœ„ë°˜ì´ì—ìš”
   - í†µìƒì ìœ¼ë¡œ "ë¬´ìƒ ìˆ˜ì • 2íšŒ, ì´í›„ ìœ ìƒ" ê°™ì€ ëª…í™•í•œ ê¸°ì¤€ì´ í•„ìš”í•´ìš”

ğŸ¯ **[ì¶œë ¥ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ - ë°˜ë“œì‹œ ì¤€ìˆ˜]**
- âŒ ê¸ˆì§€: "ë¶ˆë²• ì†Œì§€ê°€ ìˆìŠµë‹ˆë‹¤", "ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤" ê°™ì€ ì• ë§¤í•œ í‘œí˜„
- âœ… í•„ìˆ˜: ìœ„ë°˜ ì‚¬í•­ ë°œê²¬ ì‹œ **"ğŸš¨ ëª…ë°±í•œ ê·¼ë¡œê¸°ì¤€ë²• ìœ„ë°˜ì´ì—ìš”!"** ê°™ì€ ë‹¨í˜¸í•˜ë©´ì„œë„ ì¹œê·¼í•œ í‘œí˜„ ì‚¬ìš©
- âœ… ë¹„êµ í˜•ì‹: ë°˜ë“œì‹œ **[ê³„ì•½ì„œ ì›ë¬¸] vs [ê´€ë ¨ ë²•ë¥ /íŒ©íŠ¸]** í˜•íƒœë¡œ ëŒ€ì¡°í•´ì„œ ì„¤ëª…
  ì˜ˆì‹œ:
  - ê³„ì•½ì„œ: "ì›”ê¸‰ 150ë§Œì› (ì£¼ 40ì‹œê°„, ì›” 4ì£¼)"
  - ê³„ì‚°: 150ë§Œì› Ã· 160ì‹œê°„ = 9,375ì›/ì‹œê°„
  - ë²•ë¥ : 2025ë…„ ìµœì €ì‹œê¸‰ 10,030ì›
  - ê²°ë¡ : ğŸš¨ ëª…ë°±í•œ ìµœì €ì„ê¸ˆë²• ìœ„ë°˜ì´ì—ìš”! (655ì› ë¶€ì¡±í•´ìš”)

ë¶„ì„ ì‹œ ì¶”ê°€ í™•ì¸ ì‚¬í•­:
1. ê·¼ë¡œì‹œê°„ ë° íœ´ê²Œì‹œê°„ (ê·¼ë¡œê¸°ì¤€ë²• ì œ50ì¡°, ì œ54ì¡°)
2. ì„ê¸ˆ ë° ìˆ˜ë‹¹ (ê·¼ë¡œê¸°ì¤€ë²• ì œ43ì¡°, ì œ56ì¡°)
3. í•´ê³  ì˜ˆê³  (ê·¼ë¡œê¸°ì¤€ë²• ì œ26ì¡°)
4. ì—°ì°¨íœ´ê°€ (ê·¼ë¡œê¸°ì¤€ë²• ì œ60ì¡°)
5. ê¸°íƒ€ ë¶ˆë¦¬í•˜ê±°ë‚˜ ëˆ„ë½ëœ ì¡°í•­

**ğŸ¨ [ì¶œë ¥ í˜•ì‹ (JSON)]**
ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”:

{{
    "extracted_text": "ì¤„ë°”ê¿ˆì´ êµì •ëœ ê³„ì•½ì„œ ì›ë¬¸",
    "risk_clauses": [
        {{
            "category": "ğŸš¨ ìœ„ë°˜ í•­ëª© ì œëª© (ì˜ˆ: í‡´ì§ê¸ˆ ë¯¸ì§€ê¸‰ ì¡°í•­)",
            "original_text": "ë¬¸ì œê°€ ëœ ê³„ì•½ì„œ ë¬¸êµ¬ (í•˜ì´ë¼ì´íŠ¸ìš© - extracted_textì— í¬í•¨ëœ ì •í™•í•œ ë¬¸ì¥)",
            "explanation": "ì´ê²Œ ì™œ ë¬¸ì œì¸ì§€ ì¹œêµ¬ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´ ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì‘ì„± (í•´ìš”ì²´ í•„ìˆ˜! ë²•ì  ê·¼ê±°ë„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨)",
            "script": "ì‚¬ì¥ë‹˜ê»˜ ë³´ë‚¼ ì •ì¤‘í•˜ì§€ë§Œ ë‹¨í˜¸í•œ ìš”ì²­ ë©”ì‹œì§€ (ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì“¸ ìˆ˜ ìˆê²Œ)"
        }}
    ],
    "summary": "ì „ì²´ì ì¸ ì´í‰ (ì˜ˆ: 'ì „ë°˜ì ìœ¼ë¡œ ê´œì°®ì§€ë§Œ, 3ì¡°ëŠ” ê¼­ ì§šê³  ë„˜ì–´ê°€ì•¼ í•´ìš”! ê¼¼ê¼¼íˆ ì±™ê²¨ì„œ ì†í•´ë³´ì§€ ë§ìê³ ìš” ğŸ’ª')"
}}

**ì¤‘ìš”:**
- original_textëŠ” ë°˜ë“œì‹œ extracted_textì— í¬í•¨ëœ ì •í™•í•œ ë¬¸ì¥ì´ì–´ì•¼ í•´ìš” (í•˜ì´ë¼ì´íŠ¸ í‘œì‹œì— ì‚¬ìš©)
- categoryëŠ” ì´ëª¨ì§€ë¥¼ í¬í•¨í•œ ê°„ê²°í•œ ì œëª©ìœ¼ë¡œ (ğŸš¨ ìœ„í—˜, âš ï¸ ì£¼ì˜, ğŸ’¡ ì°¸ê³ )
- explanationì€ ë²•ì  ê·¼ê±°ë¥¼ í¬í•¨í•˜ë˜ ì¹œêµ¬ì—ê²Œ ì„¤ëª…í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±
- scriptëŠ” ì‹¤ì œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì •ì¤‘í•˜ê³  ëª…í™•í•œ ìš”ì²­ ë¬¸êµ¬ë¡œ
- summaryëŠ” ê³µê°ê³¼ ì‘ì›ì´ ë‹´ê¸´ ì¹œê·¼í•œ ì´í‰ìœ¼ë¡œ

ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ëª¨ë“  ì„¤ëª…ì€ **í•´ìš”ì²´**ë¡œ ì¹œê·¼í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    try:
        contents = []
        for idx, (image_bytes, mime_type) in enumerate(image_data_list):
            contents.append(
                types.Part.from_bytes(
                    data=image_bytes,
                    mime_type=mime_type,
                )
            )

        contents.append(system_prompt + f"\n\nìœ„ {len(image_data_list)}ì¥ì˜ ê³„ì•½ì„œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.")

        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=contents,
            config=types.GenerateContentConfig(
                temperature=0.0,  # ì¼ê´€ì„± ìˆëŠ” ë²•ë¥  ë¶„ì„ì„ ìœ„í•´ ì°½ì˜ì„± ì œí•œ
                response_mime_type="application/json",
                response_schema=ContractAnalysisResult,
            ),
        )

        raw_json = response.text
        logging.info(f"Gemini response: {raw_json}")

        if raw_json:
            data = json.loads(raw_json)
            return ContractAnalysisResult(**data)
        else:
            return None

    except Exception as e:
        logging.error(f"Contract analysis failed: {e}")
        raise Exception(f"ê³„ì•½ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


def analyze_contract_files(file_data_list: list[tuple[bytes, str]]) -> Optional[ContractAnalysisResult]:
    """
    Analyze contract files (images or PDFs) using Gemini.
    PDFs are sent directly to Gemini without conversion.
    
    Args:
        file_data_list: List of (file_bytes, mime_type) tuples
                       mime_type can be 'image/jpeg', 'image/png', or 'application/pdf'
    """
    
    if DEMO_MODE:
        return get_demo_result()
    
    if len(file_data_list) == 1 and file_data_list[0][1] != 'application/pdf':
        return analyze_contract_image(file_data_list[0][0], file_data_list[0][1])
    
    from google import genai
    from google.genai import types
    
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise EnvironmentError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    client = genai.Client(api_key=api_key)
    
    system_prompt = """ë‹¹ì‹ ì€ í•œêµ­ ê·¼ë¡œê¸°ì¤€ë²• ì „ë¬¸ê°€ì´ì ê³„ì•½ì„œ ë¶„ì„ AIì…ë‹ˆë‹¤.

**ì‘ì—… 1: í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR)**
ì œê³µëœ ê³„ì•½ì„œ íŒŒì¼(ì´ë¯¸ì§€ ë˜ëŠ” PDF)ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.
ì›ë³¸ í˜•ì‹(ì¤„ë°”ê¿ˆ, ë²ˆí˜¸ ë“±)ì„ ìµœëŒ€í•œ ìœ ì§€í•˜ì„¸ìš”.

**ì‘ì—… 2: ìœ„í—˜ ì¡°í•­ ë¶„ì„**
ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ê·¼ë¡œìì—ê²Œ ë¶ˆë¦¬í•œ ì¡°í•­ì„ ì°¾ìœ¼ì„¸ìš”.

ë¶„ì„ ì‹œ í™•ì¸ ì‚¬í•­:
1. ê·¼ë¡œì‹œê°„ ë° íœ´ê²Œì‹œê°„ (ê·¼ë¡œê¸°ì¤€ë²• ì œ50ì¡°, ì œ54ì¡°)
2. ì„ê¸ˆ ë° ìˆ˜ë‹¹ (ê·¼ë¡œê¸°ì¤€ë²• ì œ43ì¡°, ì œ56ì¡°)
3. í•´ê³  ì˜ˆê³  (ê·¼ë¡œê¸°ì¤€ë²• ì œ26ì¡°)
4. ì—°ì°¨íœ´ê°€ (ê·¼ë¡œê¸°ì¤€ë²• ì œ60ì¡°)
5. ê¸°íƒ€ ë¶ˆë¦¬í•˜ê±°ë‚˜ ëˆ„ë½ëœ ì¡°í•­

**ğŸ¨ [ì¶œë ¥ í˜•ì‹ (JSON)]**
ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:

{{
    "extracted_text": "ì¤„ë°”ê¿ˆì´ êµì •ëœ ê³„ì•½ì„œ ì›ë¬¸",
    "risk_clauses": [
        {{
            "category": "ğŸš¨ ìœ„ë°˜ í•­ëª© ì œëª© (ì˜ˆ: í‡´ì§ê¸ˆ ë¯¸ì§€ê¸‰ ì¡°í•­)",
            "original_text": "ë¬¸ì œê°€ ëœ ê³„ì•½ì„œ ë¬¸êµ¬ (í•˜ì´ë¼ì´íŠ¸ìš© - extracted_textì— í¬í•¨ëœ ì •í™•í•œ ë¬¸ì¥)",
            "explanation": "ì´ê²Œ ì™œ ë¬¸ì œì¸ì§€ ì¹œêµ¬ì—ê²Œ ì„¤ëª…í•˜ë“¯ì´ ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì‘ì„± (í•´ìš”ì²´ í•„ìˆ˜! ë²•ì  ê·¼ê±°ë„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨)",
            "script": "ì‚¬ì¥ë‹˜ê»˜ ë³´ë‚¼ ì •ì¤‘í•˜ì§€ë§Œ ë‹¨í˜¸í•œ ìš”ì²­ ë©”ì‹œì§€ (ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì“¸ ìˆ˜ ìˆê²Œ)"
        }}
    ],
    "summary": "ì „ì²´ì ì¸ ì´í‰ (ì˜ˆ: 'ì „ë°˜ì ìœ¼ë¡œ ê´œì°®ì§€ë§Œ, 3ì¡°ëŠ” ê¼­ ì§šê³  ë„˜ì–´ê°€ì•¼ í•´ìš”! ê¼¼ê¼¼íˆ ì±™ê²¨ì„œ ì†í•´ë³´ì§€ ë§ìê³ ìš” ğŸ’ª')"
}}

**ì¤‘ìš”:**
- original_textëŠ” ë°˜ë“œì‹œ extracted_textì— í¬í•¨ëœ ì •í™•í•œ ë¬¸ì¥ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (í•˜ì´ë¼ì´íŠ¸ í‘œì‹œì— ì‚¬ìš©)
- categoryëŠ” ì´ëª¨ì§€ë¥¼ í¬í•¨í•œ ê°„ê²°í•œ ì œëª©ìœ¼ë¡œ (ğŸš¨ ìœ„í—˜, âš ï¸ ì£¼ì˜, ğŸ’¡ ì°¸ê³ )
- explanationì€ ë²•ì  ê·¼ê±°ë¥¼ í¬í•¨í•˜ë˜ ì¹œêµ¬ì—ê²Œ ì„¤ëª…í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±
- scriptëŠ” ì‹¤ì œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì •ì¤‘í•˜ê³  ëª…í™•í•œ ìš”ì²­ ë¬¸êµ¬ë¡œ
- summaryëŠ” ê³µê°ê³¼ ì‘ì›ì´ ë‹´ê¸´ ì¹œê·¼í•œ ì´í‰ìœ¼ë¡œ

ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

    try:
        contents = []
        for idx, (file_bytes, mime_type) in enumerate(file_data_list):
            contents.append(
                types.Part.from_bytes(
                    data=file_bytes,
                    mime_type=mime_type,
                )
            )
        
        file_count = len(file_data_list)
        contents.append(system_prompt + f"\n\nìœ„ {file_count}ê°œì˜ ê³„ì•½ì„œ íŒŒì¼ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.")
        
        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=contents,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=ContractAnalysisResult,
            ),
        )
        
        raw_json = response.text
        logging.info(f"Gemini response: {raw_json}")
        
        if raw_json:
            data = json.loads(raw_json)
            return ContractAnalysisResult(**data)
        else:
            return None
            
    except Exception as e:
        logging.error(f"Contract analysis failed: {e}")
        raise Exception(f"ê³„ì•½ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


def get_risk_color(category: str) -> str:
    """Return background color based on category emoji (Modern premium design)."""
    if "ğŸš¨" in category:
        return "#FEF2F2"
    elif "âš ï¸" in category:
        return "#FFFBEB"
    elif "ğŸ’¡" in category:
        return "#ECFDF5"
    return "#FFFBEB"

def get_risk_border_color(category: str) -> str:
    """Return border/accent color based on category emoji (Modern premium design)."""
    if "ğŸš¨" in category:
        return "#DC2626"
    elif "âš ï¸" in category:
        return "#F59E0B"
    elif "ğŸ’¡" in category:
        return "#10B981"
    return "#F59E0B"

def get_risk_emoji(category: str) -> str:
    """Extract emoji from category."""
    if "ğŸš¨" in category:
        return "ğŸš¨"
    elif "âš ï¸" in category:
        return "âš ï¸"
    elif "ğŸ’¡" in category:
        return "ğŸ’¡"
    return "âš ï¸"

def get_risk_label(category: str) -> str:
    """Extract Korean label from category."""
    # Extract text after emoji
    if "ğŸš¨" in category:
        return "ìœ„í—˜"
    elif "âš ï¸" in category:
        return "ì£¼ì˜"
    elif "ğŸ’¡" in category:
        return "ì°¸ê³ "
    return "ì£¼ì˜"


def highlight_text_with_risks(contract_text: str, analysis: list[AnalysisItem]) -> str:
    """
    Apply inline highlights with hover tooltips and click-to-modal functionality.
    Uses pure CSS modal with checkbox hack (no JavaScript needed for Streamlit).
    Returns HTML with:
    - Highlighted risk text with colored background
    - Tooltip appearing on hover (like memo box)
    - Modal popup on click with full details (pure CSS)
    """
    import html

    safe_text = html.escape(contract_text)
    highlighted = safe_text

    modal_data_list = []

    for idx, item in enumerate(sorted(analysis, key=lambda x: len(x.original_text), reverse=True), 1):
        safe_original = html.escape(item.original_text)

        if safe_original and safe_original in highlighted:
            bg_color = get_risk_color(item.category)
            border_color = get_risk_border_color(item.category)
            emoji = get_risk_emoji(item.category)
            label = get_risk_label(item.category)

            safe_category = html.escape(item.category)
            safe_explanation = html.escape(item.explanation)
            safe_script = html.escape(item.script)

            modal_id = f"risk-modal-{idx}"
            checkbox_id = f"modal-toggle-{idx}"

            modal_data_list.append({
                "id": modal_id,
                "checkbox_id": checkbox_id,
                "emoji": emoji,
                "label": label,
                "category": safe_category,
                "original": safe_original,
                "explanation": safe_explanation,
                "script": safe_script,
                "border_color": border_color
            })

            highlight_html = f'''<span class="risk-highlight-wrapper"><label for="{checkbox_id}" class="risk-mark-label"><mark class="risk-mark" style="background: {bg_color}; border-bottom: 2px solid {border_color}; padding: 1px 2px; border-radius: 3px; cursor: pointer;">{safe_original}</mark></label><span class="risk-tooltip"><span class="tooltip-header"><span style="display:inline-block;width:8px;height:8px;background:{border_color};border-radius:50%;margin-right:6px;"></span>{label}</span><span class="tooltip-content">{safe_category}</span><span class="tooltip-hint">í´ë¦­í•˜ì—¬ ìƒì„¸ ì •ë³´ í™•ì¸</span></span></span>'''

            highlighted = highlighted.replace(safe_original, highlight_html, 1)

    return highlighted, modal_data_list


def generate_css_modals_html(modal_data_list: list) -> str:
    """Generate pure CSS modal HTML using checkbox hack."""
    modals = ""
    for data in modal_data_list:
        modals += f'''
<input type="checkbox" id="{data['checkbox_id']}" class="modal-toggle" />
<div class="css-modal-overlay">
    <label for="{data['checkbox_id']}" class="modal-overlay-bg"></label>
    <div class="modal-content">
        <div class="modal-header">
            <div class="modal-title">
                <span class="risk-badge">{data['emoji']} {data['label']}</span>
                <span class="risk-category">{data['category']}</span>
            </div>
            <label for="{data['checkbox_id']}" class="modal-close">&times;</label>
        </div>
        <div class="modal-body">
            <div class="modal-section">
                <div class="modal-section-title">ğŸ“ í•´ë‹¹ ì¡°í•­</div>
                <div class="modal-section-content modal-original-text">"{data['original']}"</div>
            </div>
            <div class="modal-section">
                <div class="modal-section-title">ğŸ’¡ ì™œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆë‚˜ìš”?</div>
                <div class="modal-section-content modal-issue-section">{data['explanation']}</div>
            </div>
            <div class="modal-section modal-script-section">
                <div class="modal-section-title">ğŸ’¬ ì´ë ‡ê²Œ ë§í•´ë³´ì„¸ìš”</div>
                <div class="modal-section-content modal-script">"{data['script']}"</div>
            </div>
        </div>
    </div>
</div>'''
    return modals


def generate_modals_html(modal_data_list: list) -> str:
    """Generate modal HTML for each risk clause."""
    modals = ""
    for data in modal_data_list:
        modals += f'''
<div id="{data['id']}" class="modal-overlay" onclick="closeModalOnOverlay(event, '{data['id']}')">
    <div class="modal-content" onclick="event.stopPropagation()">
        <div class="modal-header">
            <div class="modal-title">
                <span class="risk-badge">{data['emoji']} {data['label']}</span>
                <span class="risk-category">{data['category']}</span>
            </div>
            <button class="modal-close" onclick="closeRiskModal('{data['id']}')">&times;</button>
        </div>
        <div class="modal-body">
            <div class="modal-section">
                <div class="modal-section-title">ğŸ“ í•´ë‹¹ ì¡°í•­</div>
                <div class="modal-section-content modal-original-text">"{data['original']}"</div>
            </div>
            <div class="modal-section">
                <div class="modal-section-title">ğŸ’¡ ì™œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆë‚˜ìš”?</div>
                <div class="modal-section-content">{data['explanation']}</div>
            </div>
            <div class="modal-section">
                <div class="modal-section-title">ğŸ’¬ ì´ë ‡ê²Œ ë§í•´ë³´ì„¸ìš”</div>
                <div class="modal-section-content modal-script">"{data['script']}"</div>
            </div>
        </div>
    </div>
</div>'''
    return modals


def generate_modal_script() -> str:
    """Generate JavaScript for modal open/close functionality.
    Note: This returns empty string as Streamlit strips inline scripts.
    The actual script needs to be injected via st.components.v1.html()
    """
    return ""


def get_modal_javascript() -> str:
    """Return the JavaScript code that needs to be injected via st.components.v1.html()"""
    return '''
<script>
window.openRiskModal = function(modalId) {
    const modal = window.parent.document.getElementById(modalId);
    if (modal) {
        modal.classList.add('active');
        window.parent.document.body.style.overflow = 'hidden';
    }
};

window.closeRiskModal = function(modalId) {
    const modal = window.parent.document.getElementById(modalId);
    if (modal) {
        modal.classList.remove('active');
        window.parent.document.body.style.overflow = '';
    }
};

window.parent.document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape') {
        const modals = window.parent.document.querySelectorAll('.modal-overlay.active');
        modals.forEach(function(modal) {
            modal.classList.remove('active');
        });
        window.parent.document.body.style.overflow = '';
    }
});
</script>
'''


def generate_annotation_cards(analysis: list[AnalysisItem]) -> str:
    """
    Generate expandable annotation cards for each risk clause.
    These appear below the document as clickable cards.
    """
    import html

    if not analysis:
        return ""

    cards_html = '<div class="annotation-cards">'

    for idx, item in enumerate(analysis, 1):
        bg_color = get_risk_color(item.category)
        border_color = get_risk_border_color(item.category)
        emoji = get_risk_emoji(item.category)
        label = get_risk_label(item.category)

        safe_original = html.escape(item.original_text)
        safe_category = html.escape(item.category)
        safe_explanation = html.escape(item.explanation)
        safe_script = html.escape(item.script)

        cards_html += f'''
<details class="annotation-card" style="border-left: 4px solid {border_color};">
<summary class="annotation-summary" style="background: {bg_color};">
<span class="annotation-number" style="background: {border_color};">{idx}</span>
<span class="annotation-title">{safe_category}</span>
</summary>
<div class="annotation-detail">
<div class="annotation-quote">
<strong>ğŸ“ í•´ë‹¹ ë¬¸êµ¬:</strong><br>
"{safe_original}"
</div>
<div class="annotation-section">
<div class="annotation-label">ğŸ’¡ ì™œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆë‚˜ìš”?</div>
<div class="annotation-content">{safe_explanation}</div>
</div>
<div class="annotation-section">
<div class="annotation-label">ğŸ’¬ ì´ë ‡ê²Œ ë§í•´ë³´ì„¸ìš”</div>
<div class="annotation-script">"{safe_script}"</div>
</div>
</div>
</details>'''

    cards_html += '</div>'
    return cards_html


# ============================================================
# VECTOR DB FUNCTIONS (For chat_with_contract RAG system)
# ============================================================

def build_vector_db(data_folder: str = "./data", persist_directory: str = "./chroma_db") -> Optional[Chroma]:
    """
    Build ChromaDB vector database from PDF files in data folder.

    Args:
        data_folder: Path to folder containing PDF files
        persist_directory: Path to persist the vector database

    Returns:
        Chroma vectorstore instance or None if build fails
    """
    if not VECTOR_DB_AVAILABLE:
        logging.error("Vector DB dependencies not installed. Run: pip install langchain langchain-community langchain-google-genai langchain-chroma chromadb pypdf")
        return None

    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise EnvironmentError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    print(f"ğŸ“‚ Scanning PDF files in {data_folder}...")

    # Get all PDF files
    pdf_files = [f for f in os.listdir(data_folder) if f.endswith('.pdf')]

    if not pdf_files:
        print(f"âŒ No PDF files found in {data_folder}")
        return None

    print(f"âœ… Found {len(pdf_files)} PDF files")

    # Load and split documents
    all_documents = []
    total_pages = 0

    for pdf_file in pdf_files:
        pdf_path = os.path.join(data_folder, pdf_file)
        print(f"   ğŸ“„ Loading {pdf_file}...")

        try:
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()
            total_pages += len(documents)
            all_documents.extend(documents)
            print(f"      âœ“ {len(documents)} pages loaded")
        except Exception as e:
            print(f"      âœ— Error loading {pdf_file}: {e}")
            continue

    if not all_documents:
        print("âŒ No documents loaded")
        return None

    print(f"\nğŸ“Š Total: {len(pdf_files)} files, {total_pages} pages")
    print(f"ğŸ”ª Splitting documents into chunks...")

    # Split documents into chunks
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
    )

    splits = text_splitter.split_documents(all_documents)
    print(f"âœ… Created {len(splits)} chunks")

    # Create embeddings and vector store
    print(f"ğŸ§® Creating embeddings with Gemini...")
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=api_key
    )

    print(f"ğŸ’¾ Building ChromaDB vector store at {persist_directory}...")
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embeddings,
        persist_directory=persist_directory
    )

    print(f"âœ… Vector DB built successfully!")
    print(f"   ğŸ“Š Files: {len(pdf_files)} | Pages: {total_pages} | Chunks: {len(splits)}")

    return vectorstore


def get_vector_store(persist_directory: str = "./chroma_db") -> Optional[Chroma]:
    """
    Load existing ChromaDB vector store.

    Args:
        persist_directory: Path to persisted vector database

    Returns:
        Chroma vectorstore instance or None if not found
    """
    if not VECTOR_DB_AVAILABLE:
        logging.warning("Vector DB dependencies not available")
        return None

    if not os.path.exists(persist_directory):
        logging.warning(f"Vector DB not found at {persist_directory}. Run build_db.py first.")
        return None

    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise EnvironmentError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=api_key
    )

    vectorstore = Chroma(
        persist_directory=persist_directory,
        embedding_function=embeddings
    )

    return vectorstore


def chat_with_contract(question: str, contract_text: str = "", use_rag: bool = True) -> dict:
    """
    RAG-based chat function for answering questions about labor law.

    Args:
        question: User's question
        contract_text: Optional contract text for context
        use_rag: Whether to use RAG (vector DB search) or direct answer

    Returns:
        dict with 'answer' and 'sources' keys
    """
    from google import genai
    from google.genai import types

    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise EnvironmentError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    client = genai.Client(api_key=api_key)

    # Build context from RAG if enabled
    context_sources = []
    if use_rag and VECTOR_DB_AVAILABLE:
        vectorstore = get_vector_store()
        if vectorstore:
            # Search for relevant documents
            retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
            docs = retriever.invoke(question)  # Updated method name for newer langchain
            context_sources = [doc.page_content for doc in docs]

    # Build prompt
    system_prompt = """ë‹¹ì‹ ì€ í•œêµ­ ê·¼ë¡œê¸°ì¤€ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ ì‹œ:
1. ê´€ë ¨ ë²•ì¡°í•­ì„ ëª…í™•íˆ ì¸ìš©í•˜ì„¸ìš”
2. ì‰¬ìš´ ë§ë¡œ ì„¤ëª…í•˜ì„¸ìš”
3. ì‹¤ì œ ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ë©´ ë” ì¢‹ìŠµë‹ˆë‹¤

ë‹µë³€ í˜•ì‹:
ğŸ“Œ **í•µì‹¬ ë‹µë³€**: (í•œ ë¬¸ì¥ ìš”ì•½)

âš–ï¸ **ë²•ì  ê·¼ê±°**:
(ê´€ë ¨ ë²•ì¡°í•­ ì¸ìš©)

ğŸ—£ï¸ **ì‰¬ìš´ ì„¤ëª…**:
(ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…)
"""

    user_prompt = f"ì§ˆë¬¸: {question}\n\n"

    if contract_text:
        user_prompt += f"ê³„ì•½ì„œ ë‚´ìš©:\n{contract_text}\n\n"

    if context_sources:
        user_prompt += "ì°¸ê³  ìë£Œ:\n"
        for i, source in enumerate(context_sources, 1):
            user_prompt += f"\n[ìë£Œ {i}]\n{source}\n"

    try:
        response = client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=[system_prompt + "\n\n" + user_prompt],
            config=types.GenerateContentConfig(
                temperature=0.3,  # ë²•ë¥  ìƒë‹´ì€ ì•½ê°„ì˜ ìœ ì—°ì„± í—ˆìš©
            ),
        )

        answer = response.text

        return {
            "answer": answer,
            "sources": context_sources if use_rag else [],
            "status": "success"
        }

    except Exception as e:
        logging.error(f"Chat failed: {e}")
        return {
            "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
            "sources": [],
            "status": "error"
        }
