# Backend logic for ì•Œë°”Â·ë‹¨ê¸°ê³„ì•½ ë¦¬ìŠ¤í¬ í•˜ì´ë¼ì´í„°

import os
from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.messages import HumanMessage
from PIL import Image
import pypdf
import io
import base64

# Load environment variables
load_dotenv()


def build_vector_db():
    """
    PDF íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ê³  ë²¡í„° DB(ChromaDB)ë¥¼ êµ¬ì¶•í•˜ëŠ” í•¨ìˆ˜
    """
    print("ë²¡í„° DB êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 1. DirectoryLoaderë¡œ data/ í´ë”ì˜ ëª¨ë“  .pdf íŒŒì¼ì„ ë¡œë“œ
    print("1. PDF íŒŒì¼ ë¡œë”© ì¤‘...")
    loader = DirectoryLoader(
        path="./data",
        glob="*.pdf",
        loader_cls=PyPDFLoader
    )
    documents = loader.load()
    print(f"   - ì´ {len(documents)}ê°œì˜ í˜ì´ì§€ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    # 2. RecursiveCharacterTextSplitter ì‚¬ìš©
    print("2. ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í•  ì¤‘...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    chunks = text_splitter.split_documents(documents)
    print(f"   - ì´ {len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")

    # 3. GoogleGenerativeAIEmbeddings ì‚¬ìš©
    print("3. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        raise ValueError("GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=google_api_key
    )

    # 4. Chromaë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ ê²½ë¡œ('./chroma_db')ì— ì €ì¥
    print("4. ChromaDBì— ì €ì¥ ì¤‘...")
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory="./chroma_db"
    )

    # 5. ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥
    print(f"\nì´ {len(chunks)}ê°œì˜ ë¬¸ì„œ ì¡°ê°(Chunks)ì´ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    return vectorstore


def search_db(query):
    """
    ì§ˆë¬¸ì„ ë°›ì•„ì„œ ë²¡í„° DBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜

    Args:
        query (str): ê²€ìƒ‰í•  ì§ˆë¬¸

    Returns:
        str: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì •ë¦¬í•œ ë¬¸ìì—´
    """
    print(f"ì§ˆë¬¸: {query}")
    print("ë²¡í„° DB ê²€ìƒ‰ ì¤‘...")

    # 1. GoogleGenerativeAIEmbeddings ì´ˆê¸°í™”
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        raise ValueError("GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=google_api_key
    )

    # 2. Chroma ë¡œë“œ
    vectorstore = Chroma(
        persist_directory="./chroma_db",
        embedding_function=embeddings
    )

    # 3. ìœ ì‚¬í•œ ë¬¸ì„œ 3ê°œ ê²€ìƒ‰
    results = vectorstore.similarity_search(query, k=3)

    # 4. ê²°ê³¼ ì •ë¦¬
    if not results:
        return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    output = []
    for i, doc in enumerate(results, 1):
        output.append(f"\n=== ë¬¸ì„œ {i} ===")
        output.append(f"ë‚´ìš©: {doc.page_content[:200]}...")  # ì²˜ìŒ 200ìë§Œ í‘œì‹œ
        output.append(f"ì¶œì²˜: {doc.metadata}")

    return "\n".join(output)


def get_answer(query):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ì„œ ë²¡í„° DB ê²€ìƒ‰ í›„ Geminië¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜

    Args:
        query (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸

    Returns:
        str: Geminiê°€ ìƒì„±í•œ ë‹µë³€
    """
    print(f"\nì§ˆë¬¸: {query}")

    # 1. search_dbë¥¼ í˜¸ì¶œí•´ì„œ ê´€ë ¨ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    print("ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
    context = search_db(query)

    # 2. ChatGoogleGenerativeAI ì´ˆê¸°í™”
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        raise ValueError("GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro",
        google_api_key=google_api_key,
        temperature=0.7
    )

    # 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±
    prompt = f"""ë‹¹ì‹ ì€ ì‚¬íšŒì´ˆë…„ìƒì„ ìœ„í•œ ì¹œì ˆí•œ ë²•ë¥  ë©˜í†  'í•˜ì´ë¼ì´í„°'ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ [ì°¸ê³  ë¬¸ì„œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…ì¾Œí•˜ê²Œ ë‹µí•´ì£¼ì„¸ìš”.

[ë‹µë³€ í•„ìˆ˜ í¬í•¨ í•­ëª©]
1. ğŸš¨ ì›Œë‹ ì‚¬ì¸ (ìœ„ë²• ì—¬ë¶€ íŒë‹¨)
2. ğŸ’¬ ëŒ€ì²˜ ìŠ¤í¬ë¦½íŠ¸ (ì‚¬ì¥ë‹˜ê»˜ ë³´ë‚¼ ì¹´í†¡ ë§íˆ¬ë¡œ)
3. âš–ï¸ ë²•ì  ê·¼ê±° (ì°¸ê³  ë¬¸ì„œì˜ ì¶œì²˜ í™œìš©)

[ì°¸ê³  ë¬¸ì„œ]: {context}
[ì§ˆë¬¸]: {query}
"""

    # 4. Geminië¡œ ë‹µë³€ ìƒì„±
    print("Geminiê°€ ë‹µë³€ì„ ìƒì„± ì¤‘...")
    response = llm.invoke(prompt)

    return response.content


def chat_with_contract(user_question, contract_context):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ì„œ ê³„ì•½ì„œ ë‚´ìš©ê³¼ ë²•ë¥  ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì±„íŒ… í•¨ìˆ˜

    Args:
        user_question (str): ì‚¬ìš©ìì˜ ì§ˆë¬¸
        contract_context (str): ë¶„ì„í•œ ê³„ì•½ì„œ ì›ë¬¸ í…ìŠ¤íŠ¸

    Returns:
        str: Geminiê°€ ìƒì„±í•œ ë‹µë³€
    """
    print(f"\nì±„íŒ… ì§ˆë¬¸: {user_question}")

    # 1. search_dbë¥¼ í˜¸ì¶œí•´ì„œ ê´€ë ¨ ë²•ë¥  ì§€ì‹ ê°€ì ¸ì˜¤ê¸°
    print("ê´€ë ¨ ë²•ë¥  ì§€ì‹ ê²€ìƒ‰ ì¤‘...")
    legal_knowledge = search_db(user_question)

    # 2. ChatGoogleGenerativeAI ì´ˆê¸°í™”
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        raise ValueError("GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro",
        google_api_key=google_api_key,
        temperature=0.7
    )

    # 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„± (ê³„ì•½ì„œ ë‚´ìš© + ë²•ë¥  ì§€ì‹)
    prompt = f"""ë‹¹ì‹ ì€ ì‚¬íšŒì´ˆë…„ìƒì„ ìœ„í•œ ì¹œì ˆí•œ ë²•ë¥  ë©˜í†  'í•˜ì´ë¼ì´í„°'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ìì‹ ì˜ ê³„ì•½ì„œì— ëŒ€í•´ ì¶”ê°€ ì§ˆë¬¸ì„ í–ˆìŠµë‹ˆë‹¤.
ì•„ë˜ì˜ [ê³„ì•½ì„œ ë‚´ìš©]ê³¼ [ë²•ë¥  ì§€ì‹]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…ì¾Œí•˜ê²Œ ë‹µí•´ì£¼ì„¸ìš”.

[ë‹µë³€ ê°€ì´ë“œë¼ì¸]
1. ê³„ì•½ì„œ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©í•˜ë©° ì„¤ëª…í•´ì£¼ì„¸ìš”
2. ê´€ë ¨ ë²•ë¥  ê·¼ê±°ë¥¼ í•¨ê»˜ ì œì‹œí•´ì£¼ì„¸ìš”
3. ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”
4. ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë§íˆ¬ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”

[ê³„ì•½ì„œ ë‚´ìš©]
{contract_context[:3000]}

[ë²•ë¥  ì§€ì‹]
{legal_knowledge}

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_question}
"""

    # 4. Geminië¡œ ë‹µë³€ ìƒì„±
    print("Geminiê°€ ë‹µë³€ì„ ìƒì„± ì¤‘...")
    response = llm.invoke(prompt)

    return response.content


def generate_suggested_questions(contract_text):
    """
    ê³„ì•½ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¼ ë§Œí•œ ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜

    Args:
        contract_text (str): ê³„ì•½ì„œ ì›ë¬¸ í…ìŠ¤íŠ¸

    Returns:
        list: ì¶”ì²œ ì§ˆë¬¸ 3ê°œì˜ ë¦¬ìŠ¤íŠ¸
    """
    print("\nì¶”ì²œ ì§ˆë¬¸ ìƒì„± ì¤‘...")

    # Google API Key í™•ì¸
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        raise ValueError("GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # ChatGoogleGenerativeAI ì´ˆê¸°í™”
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        google_api_key=google_api_key,
        temperature=0.7
    )

    # ì¶”ì²œ ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸
    prompt = f"""ë‹¹ì‹ ì€ ì‚¬íšŒì´ˆë…„ìƒì„ ìœ„í•œ ë²•ë¥  ë©˜í† ì…ë‹ˆë‹¤.
ì•„ë˜ ê³„ì•½ì„œë¥¼ ë³´ê³ , ì‚¬ìš©ìê°€ ì¶”ê°€ë¡œ ë¬¼ì–´ë³¼ ë§Œí•œ êµ¬ì²´ì ì¸ ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

[ê³„ì•½ì„œ ë‚´ìš©]
{contract_text[:2000]}

[ìš”êµ¬ì‚¬í•­]
- ê³„ì•½ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”
- ìµœì €ì„ê¸ˆ, ê·¼ë¡œì‹œê°„, ìˆ˜ë‹¹, ê³„ì•½ ì¡°ê±´ ë“± ì‹¤ì œë¡œ ì¤‘ìš”í•œ ì‚¬í•­ì— ëŒ€í•œ ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤
- ì§ˆë¬¸ì€ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
- ë°˜ë“œì‹œ ì •í™•íˆ 3ê°œì˜ ì§ˆë¬¸ë§Œ ìƒì„±í•´ì£¼ì„¸ìš”
- ê° ì§ˆë¬¸ì€ í•œ ì¤„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”

ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ì§€ì¼œì£¼ì„¸ìš”):
1. ì²« ë²ˆì§¸ ì§ˆë¬¸
2. ë‘ ë²ˆì§¸ ì§ˆë¬¸
3. ì„¸ ë²ˆì§¸ ì§ˆë¬¸"""

    # LLM í˜¸ì¶œ
    response = llm.invoke(prompt)
    generated_text = response.content

    # ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
    questions = []
    for line in generated_text.split('\n'):
        line = line.strip()
        # "1.", "2.", "3." í˜•ì‹ì˜ ì¤„ ì°¾ê¸°
        if line and (line.startswith('1.') or line.startswith('2.') or line.startswith('3.')):
            # ë²ˆí˜¸ ì œê±°í•˜ê³  ì§ˆë¬¸ë§Œ ì¶”ì¶œ
            question = line[2:].strip()
            if question:
                questions.append(question)

    # ì •í™•íˆ 3ê°œê°€ ì•„ë‹ˆë©´ ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©
    if len(questions) != 3:
        print(f"Warning: LLMì´ {len(questions)}ê°œì˜ ì§ˆë¬¸ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§ˆë¬¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        questions = [
            "ìµœì €ì„ê¸ˆ ê³„ì‚°ì´ ë§ë‚˜ìš”?",
            "ì£¼íœ´ìˆ˜ë‹¹ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ìˆ˜ìŠµê¸°ê°„ ì¡°í•­ì´ ì ë²•í•œê°€ìš”?"
        ]

    print(f"ìƒì„±ëœ ì¶”ì²œ ì§ˆë¬¸: {questions}")
    return questions


def analyze_contract(file_obj):
    """
    ê³„ì•½ì„œ íŒŒì¼(ì´ë¯¸ì§€ ë˜ëŠ” PDF)ì„ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜

    Args:
        file_obj: Streamlitì˜ st.file_uploaderê°€ ë°˜í™˜í•˜ëŠ” íŒŒì¼ ê°ì²´

    Returns:
        dict: ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
            - "analysis": ê³„ì•½ì„œ ë¶„ì„ ê²°ê³¼ (ì›Œë‹ì‚¬ì¸+ìŠ¤í¬ë¦½íŠ¸+ë²•ì ê·¼ê±°)
            - "contract_text": ì¶”ì¶œëœ ê³„ì•½ì„œ ì›ë¬¸ í…ìŠ¤íŠ¸
            - "suggested_questions": LLMì´ ìƒì„±í•œ ì¶”ì²œ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ (3ê°œ)
    """
    print(f"\nê³„ì•½ì„œ ë¶„ì„ ì‹œì‘: {file_obj.name}")

    # 1. íŒŒì¼ íƒ€ì… í™•ì¸
    file_type = file_obj.type
    print(f"íŒŒì¼ íƒ€ì…: {file_type}")

    extracted_text = ""

    # 2. ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš° (JPEG, PNG ë“±)
    if file_type.startswith("image/"):
        print("ì´ë¯¸ì§€ íŒŒì¼ ê°ì§€ - Gemini Visionìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")

        # Google API Key í™•ì¸
        google_api_key = os.getenv("GOOGLE_API_KEY")
        if not google_api_key:
            raise ValueError("GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # PILë¡œ ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(file_obj)

        # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
        buffered = io.BytesIO()
        image.save(buffered, format=image.format or "PNG")
        image_bytes = buffered.getvalue()

        # Base64ë¡œ ì¸ì½”ë”©
        image_base64 = base64.b64encode(image_bytes).decode("utf-8")

        # ChatGoogleGenerativeAIë¡œ Vision ëª¨ë¸ ì´ˆê¸°í™”
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            google_api_key=google_api_key,
            temperature=0.2
        )

        # ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
        text_prompt = """ì´ ì´ë¯¸ì§€ëŠ” ê³„ì•½ì„œì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ì— ìˆëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ê³„ì•½ ë‚´ìš©, ì¡°í•­, ë‚ ì§œ, ì„œëª…ë€ ë“± ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë¹ ì§ì—†ì´ ì¶”ì¶œí•´ì£¼ì„¸ìš”."""

        # HumanMessageë¡œ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ í•¨ê»˜ ì „ë‹¬
        message = HumanMessage(
            content=[
                {"type": "text", "text": text_prompt},
                {
                    "type": "image_url",
                    "image_url": f"data:image/{image.format or 'png'};base64,{image_base64}"
                }
            ]
        )

        # LLM í˜¸ì¶œ
        response = llm.invoke([message])
        extracted_text = response.content
        print(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(extracted_text)} ê¸€ì")

    # 3. PDF íŒŒì¼ì¸ ê²½ìš°
    elif file_type == "application/pdf":
        print("PDF íŒŒì¼ ê°ì§€ - pypdfë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")

        # íŒŒì¼ ê°ì²´ë¥¼ ë°”ì´íŠ¸ë¡œ ì½ê¸°
        pdf_bytes = file_obj.read()
        pdf_file = io.BytesIO(pdf_bytes)

        # pypdfë¡œ PDF ì½ê¸°
        pdf_reader = pypdf.PdfReader(pdf_file)

        # ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for page_num, page in enumerate(pdf_reader.pages, 1):
            page_text = page.extract_text()
            extracted_text += page_text + "\n"
            print(f"í˜ì´ì§€ {page_num} ì¶”ì¶œ ì™„ë£Œ")

        print(f"ì´ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(extracted_text)} ê¸€ì")

    else:
        return {
            "analysis": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_type}\nì§€ì› í˜•ì‹: ì´ë¯¸ì§€(JPG, PNG), PDF",
            "contract_text": "",
            "suggested_questions": []
        }

    # 4. ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°˜í™˜
    if not extracted_text.strip():
        return {
            "analysis": "í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "contract_text": "",
            "suggested_questions": []
        }

    # 5. get_answer() í•¨ìˆ˜ë¡œ ê³„ì•½ì„œ ë¶„ì„
    print("\nê³„ì•½ì„œ ë‚´ìš©ì„ ë¶„ì„ ì¤‘...")
    analysis_query = f"""ë‹¤ìŒì€ ê³„ì•½ì„œì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ê³„ì•½ì„œë¥¼ ë¶„ì„í•´ì„œ ì‚¬íšŒì´ˆë…„ìƒì´ ì£¼ì˜í•´ì•¼ í•  ìœ„í—˜ ìš”ì†Œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

[ê³„ì•½ì„œ ë‚´ìš©]
{extracted_text}

ìœ„ ê³„ì•½ì„œì—ì„œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì„ ì°¾ì•„ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”."""

    analysis_result = get_answer(analysis_query)

    # 6. ì¶”ì²œ ì§ˆë¬¸ ìƒì„±
    suggested_questions = generate_suggested_questions(extracted_text)

    # 7. Dictionary í˜•íƒœë¡œ ê²°ê³¼ ë°˜í™˜
    return {
        "analysis": analysis_result,
        "contract_text": extracted_text,
        "suggested_questions": suggested_questions
    }
